Search.setIndex({"docnames": ["about/authors", "about/changelog", "about/index", "api/_autosummary/lmflow.args", "autoapi/index", "autoapi/lmflow/args/index", "autoapi/lmflow/datasets/dataset/index", "autoapi/lmflow/datasets/index", "autoapi/lmflow/index", "autoapi/lmflow/models/auto_model/index", "autoapi/lmflow/models/base_model/index", "autoapi/lmflow/models/decoder_model/index", "autoapi/lmflow/models/encoder_decoder_model/index", "autoapi/lmflow/models/hf_decoder_model/index", "autoapi/lmflow/models/hf_encoder_decoder_model/index", "autoapi/lmflow/models/index", "autoapi/lmflow/models/interfaces/index", "autoapi/lmflow/models/interfaces/tunable/index", "autoapi/lmflow/models/regression_model/index", "autoapi/lmflow/models/text_regression_model/index", "autoapi/lmflow/pipeline/auto_pipeline/index", "autoapi/lmflow/pipeline/base_aligner/index", "autoapi/lmflow/pipeline/base_pipeline/index", "autoapi/lmflow/pipeline/base_tuner/index", "autoapi/lmflow/pipeline/evaluator/index", "autoapi/lmflow/pipeline/finetuner/index", "autoapi/lmflow/pipeline/index", "autoapi/lmflow/pipeline/inferencer/index", "autoapi/lmflow/pipeline/raft_aligner/index", "autoapi/lmflow/pipeline/utils/index", "autoapi/lmflow/pipeline/utils/raft_trainer/index", "autoapi/lmflow/utils/constants/index", "autoapi/lmflow/utils/data_utils/index", "autoapi/lmflow/utils/flash_attention/gpt_neo_flash_attention/index", "autoapi/lmflow/utils/flash_attention/index", "autoapi/lmflow/utils/flash_attention/llama_flash_attention/index", "autoapi/lmflow/utils/index", "autoapi/lmflow/version/index", "blogs/benchmark", "blogs/index", "examples/DATASETS", "examples/TASK_GUIDE", "examples/checkpoints", "examples/index", "examples/medical_finetune", "examples/raft", "examples/reward_modeling", "index"], "filenames": ["about/authors.md", "about/changelog.md", "about/index.md", "api/_autosummary/lmflow.args.rst", "autoapi/index.rst", "autoapi/lmflow/args/index.rst", "autoapi/lmflow/datasets/dataset/index.rst", "autoapi/lmflow/datasets/index.rst", "autoapi/lmflow/index.rst", "autoapi/lmflow/models/auto_model/index.rst", "autoapi/lmflow/models/base_model/index.rst", "autoapi/lmflow/models/decoder_model/index.rst", "autoapi/lmflow/models/encoder_decoder_model/index.rst", "autoapi/lmflow/models/hf_decoder_model/index.rst", "autoapi/lmflow/models/hf_encoder_decoder_model/index.rst", "autoapi/lmflow/models/index.rst", "autoapi/lmflow/models/interfaces/index.rst", "autoapi/lmflow/models/interfaces/tunable/index.rst", "autoapi/lmflow/models/regression_model/index.rst", "autoapi/lmflow/models/text_regression_model/index.rst", "autoapi/lmflow/pipeline/auto_pipeline/index.rst", "autoapi/lmflow/pipeline/base_aligner/index.rst", "autoapi/lmflow/pipeline/base_pipeline/index.rst", "autoapi/lmflow/pipeline/base_tuner/index.rst", "autoapi/lmflow/pipeline/evaluator/index.rst", "autoapi/lmflow/pipeline/finetuner/index.rst", "autoapi/lmflow/pipeline/index.rst", "autoapi/lmflow/pipeline/inferencer/index.rst", "autoapi/lmflow/pipeline/raft_aligner/index.rst", "autoapi/lmflow/pipeline/utils/index.rst", "autoapi/lmflow/pipeline/utils/raft_trainer/index.rst", "autoapi/lmflow/utils/constants/index.rst", "autoapi/lmflow/utils/data_utils/index.rst", "autoapi/lmflow/utils/flash_attention/gpt_neo_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/llama_flash_attention/index.rst", "autoapi/lmflow/utils/index.rst", "autoapi/lmflow/version/index.rst", "blogs/benchmark.md", "blogs/index.md", "examples/DATASETS.md", "examples/TASK_GUIDE.md", "examples/checkpoints.md", "examples/index.md", "examples/medical_finetune.md", "examples/raft.md", "examples/reward_modeling.md", "index.md"], "titles": ["Contributors", "Changelog", "About", "lmflow.args", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.args</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets.dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.auto_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.base_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.encoder_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_encoder_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces.tunable</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.text_regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.auto_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_tuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.evaluator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.finetuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.inferencer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.raft_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils.raft_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.data_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.gpt_neo_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.llama_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.version</span></code>", "LMFlow Benchmark: An Automatic Evaluation Framework for Open-Source LLMs", "Blogs", "Dataset", "LMFlow Benchmark Guide", "Checkpoints", "Examples", "Finetune", "Reward rAnked FineTuning (RAFT)", "Reward Modeling", "LMFlow"], "terms": {"shizh": [0, 47], "diao": [0, 47], "rui": [0, 47], "pan": [0, 47], "hanz": [0, 47], "dong": [0, 47], "ka": 0, "shun": 0, "shum": [0, 47], "jipeng": [0, 47], "zhang": [0, 47], "wei": [0, 47], "xiong": [0, 47], "tong": [0, 47], "The": [1, 5, 6, 7, 11, 12, 13, 14, 20, 24, 25, 27, 28, 30, 32, 38, 40, 45, 46, 47], "first": [1, 30, 38, 41, 42, 46], "public": 1, "task": [1, 13, 14, 30, 38, 43], "tune": [1, 13, 14, 23, 25, 30, 38, 44, 45, 46], "instruct": [1, 46], "user": [1, 38, 40, 41, 45, 47], "defin": [1, 3, 5, 6, 7, 30, 40, 45], "dataset": [1, 3, 4, 5, 8, 13, 14, 19, 21, 23, 24, 25, 27, 28, 30, 32, 38, 43, 44, 45, 46, 47], "A": [1, 6, 7, 11, 12, 13, 14, 19, 21, 23, 24, 28, 30, 32, 38, 46], "simpl": [1, 30, 38, 46], "extens": [1, 45, 47], "api": [1, 38, 47], "develop": [1, 38], "effici": [1, 38, 47], "finetun": [1, 4, 8, 26, 38, 40, 42, 47], "lora": [1, 13, 14, 45, 46, 47], "simplifi": [1, 24, 25, 27, 28, 46, 47], "model": [1, 3, 4, 5, 8, 21, 23, 24, 25, 27, 28, 30, 38, 40, 42, 43, 44, 45, 47], "infer": [1, 13, 14, 19, 24, 27, 40, 47], "framework": [1, 39, 45, 46], "changelog": [2, 47], "version": [2, 3, 4, 5, 8, 38], "0": [2, 8, 13, 24, 27, 28, 30, 37, 38, 42, 46, 47], "1": [2, 4, 5, 6, 7, 8, 13, 24, 30, 37, 38, 40, 43, 44, 47], "mar": 2, "28": [2, 47], "2023": [2, 38, 47], "contributor": [2, 47], "thi": [3, 4, 5, 6, 7, 11, 12, 13, 14, 28, 30, 32, 38, 40, 41, 45, 46, 47], "script": [3, 5, 30, 42, 44, 45, 46], "dataclass": [3, 5], "modelargu": [3, 5, 24, 25, 27, 28, 44], "datasetargu": [3, 5, 6, 7, 24, 25, 27, 28, 44], "contain": [3, 4, 5, 6, 7, 11, 12, 24, 25, 27, 28, 30, 38, 40], "argument": [3, 5, 6, 7, 13, 14, 19, 24, 25, 27, 28, 30, 32, 44], "us": [3, 5, 10, 11, 12, 13, 14, 17, 18, 22, 24, 30, 31, 32, 38, 40, 41, 42, 43, 45, 46, 47], "train": [3, 5, 13, 14, 25, 28, 30, 32, 38, 40, 41, 45, 46, 47], "It": [3, 5, 13, 14, 24, 30, 38, 46, 47], "import": [3, 5, 24, 30, 38, 44, 45, 47], "sever": [3, 5, 13, 14, 30, 32, 38, 40, 41, 43], "modul": 3, "includ": [3, 5, 6, 7, 30, 32, 38, 46, 47], "field": [3, 5, 46, 47], "from": [3, 5, 6, 7, 13, 14, 24, 30, 32, 38, 42, 44, 45, 46, 47], "type": [3, 5, 6, 7, 9, 19, 30, 38, 40, 41, 45, 46], "option": [3, 5, 6, 7, 11, 12, 13, 14, 19, 25, 28, 30, 35, 38, 42], "require_vers": [3, 5], "transform": [3, 5, 13, 14, 30, 44], "util": [3, 4, 5, 8, 26, 28, 38, 47], "model_for_causal_lm_map": [3, 5], "trainingargu": [3, 5, 30], "model_config_class": [3, 5], "i": [3, 5, 13, 14, 21, 23, 24, 28, 30, 38, 40, 42, 45, 46, 47], "assign": [3, 5], "list": [3, 5, 13, 14, 30, 32, 40, 47], "config": [3, 5, 44, 46], "class": 3, "model_typ": [3, 5], "tupl": [3, 5, 30, 35], "extract": [3, 5, 32], "page": [4, 38, 47], "auto": [4, 5], "gener": [4, 5, 13, 14, 18, 24, 28, 30, 32, 38, 42, 43, 45, 46, 47], "document": [4, 30, 38], "lmflow": [4, 39, 43, 44, 45, 46], "interfac": [4, 8, 13, 14, 15], "tunabl": [4, 8, 13, 14, 15, 16, 23], "auto_model": [4, 8, 15], "base_model": [4, 8, 11, 12, 15, 18], "decoder_model": [4, 8, 13, 15], "encoder_decoder_model": [4, 8, 14, 15], "hf_decoder_model": [4, 8, 15], "hf_encoder_decoder_model": [4, 8, 15], "regression_model": [4, 8, 15, 19], "text_regression_model": [4, 8, 15], "pipelin": [4, 8, 40, 44, 45, 47], "raft_train": [4, 8, 26, 29], "auto_pipelin": [4, 8, 26, 44], "base_align": [4, 8, 26, 28], "base_pipelin": [4, 8, 21, 23, 24, 26, 27], "base_tun": [4, 8, 25, 26], "evalu": [4, 5, 8, 26, 30, 39, 40, 42, 46, 47], "inferenc": [4, 5, 8, 26, 40], "raft_align": [4, 8, 26, 45], "flash_attent": [4, 8, 36], "gpt_neo_flash_attent": [4, 8, 34, 36], "llama_flash_attent": [4, 8, 34, 36], "constant": [4, 8, 36], "data_util": [4, 8, 36], "arg": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23, 25, 28, 30, 32, 44], "creat": [4, 6, 7, 10, 11, 12, 17, 18, 22, 24, 30, 43, 46, 47], "sphinx": 4, "autoapi": 4, "sourc": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 37, 39, 40, 47], "decor": 5, "paramet": [5, 6, 7, 13, 14, 19, 24, 25, 27, 28, 30, 32, 46, 47], "can": [5, 13, 14, 30, 38, 40, 41, 42, 45, 46, 47], "configur": 5, "model_name_or_path": [5, 41, 42, 46], "str": [5, 6, 7, 13, 14, 27, 30, 32, 45], "string": [5, 6, 7, 13, 14, 27, 30, 32], "repres": [5, 6, 7, 13, 14, 24], "path": [5, 13, 14, 19, 30, 41, 42, 44], "name": [5, 13, 14, 19, 20, 30, 32, 38, 41], "pretrain": [5, 13, 14, 30, 38, 42, 47], "checkpoint": [5, 30, 38, 43, 45], "weight": [5, 24, 47], "initi": [5, 6, 7, 13, 14, 19, 24, 25, 27, 28, 30, 44], "If": [5, 30, 32, 38, 41, 44, 46, 47], "none": [5, 6, 7, 13, 14, 24, 28, 30, 32, 33, 35, 46], "scratch": 5, "provid": [5, 10, 11, 12, 13, 14, 17, 18, 22, 24, 30, 38, 40, 41, 43, 45, 46, 47], "config_overrid": 5, "default": [5, 6, 7, 13, 14, 30, 32], "set": [5, 13, 14, 30, 32, 38, 40, 42, 43, 45, 46], "overrid": [5, 30], "when": [5, 30, 38, 46], "config_nam": 5, "differ": [5, 6, 7, 13, 14, 30, 38, 42], "tokenizer_nam": 5, "token": [5, 13, 14, 24, 28, 30, 38, 44, 46], "cache_dir": 5, "directori": [5, 13, 14, 24, 30, 40], "where": [5, 24, 38, 40, 45, 46], "download": [5, 38, 40, 41, 42, 45], "huggingfac": [5, 6, 7, 13, 14, 42, 46], "co": 5, "store": 5, "use_fast_token": 5, "bool": [5, 30, 32, 35], "boolean": 5, "indic": [5, 38, 40], "whether": [5, 13, 14, 30], "fast": 5, "back": [5, 46], "librari": [5, 30], "model_revis": 5, "specif": [5, 38, 46, 47], "branch": [5, 41], "tag": [5, 30], "commit": [5, 30], "id": [5, 13, 14], "use_auth_token": 5, "run": [5, 24, 25, 28, 30, 38, 40, 41, 42, 46], "cli": 5, "login": 5, "necessari": [5, 30, 38], "privat": 5, "torch_dtyp": 5, "dtype": [5, 30], "load": [5, 6, 7, 13, 14, 24, 25, 27, 28, 30, 32, 42], "under": [5, 30, 38, 40, 41, 45, 47], "pass": [5, 30, 38, 44, 47], "automat": [5, 9, 20, 30, 39], "deriv": 5, "": [5, 30, 38, 41, 44, 45, 46, 47], "use_ram_optimized_load": [5, 41], "disk": 5, "map": [5, 6, 7, 19, 44, 46], "memori": 5, "enough": 5, "lora_model_path": [5, 42], "arch_typ": 5, "use_lora": 5, "lora_r": 5, "int": [5, 13, 14, 27, 30, 32, 46], "lora_alpha": 5, "lora_target_modul": 5, "lora_dropout": 5, "float": [5, 19, 24, 27, 30, 45], "save_aggregated_lora": 5, "use_flash_attent": 5, "__post_init__": 5, "languag": [5, 13, 14, 24, 25, 30, 38, 45, 47], "dataset_path": [5, 42, 46], "dataset_nam": [5, 41], "valu": [5, 30, 33, 41, 45], "custom": [5, 30, 40, 43, 46], "is_custom_dataset": 5, "data": [5, 6, 7, 19, 24, 25, 28, 30, 32, 38, 40, 41, 42, 45, 46, 47], "fals": [5, 13, 14, 30, 33, 35, 41, 46], "customized_cache_dir": 5, "cach": [5, 6, 7, 30], "dataset_config_nam": 5, "via": [5, 38, 45], "train_fil": 5, "input": [5, 13, 14, 19, 24, 27, 28, 30, 32, 35, 38, 40, 41, 42, 46], "file": [5, 24, 30, 32, 40, 43, 44, 47], "text": [5, 13, 14, 24, 25, 32, 38, 40, 42, 44, 45, 46], "validation_fil": 5, "perplex": [5, 38], "max_train_sampl": 5, "an": [5, 10, 11, 12, 17, 18, 22, 30, 39, 45, 46, 47], "integ": 5, "maximum": [5, 24, 25, 30], "number": [5, 24, 30, 45], "exampl": [5, 11, 12, 30, 32, 38, 40, 41, 42, 45, 47], "debug": 5, "quicker": 5, "truncat": [5, 46], "max_eval_sampl": 5, "stream": [5, 45], "enabl": 5, "mode": [5, 30], "block_siz": 5, "sequenc": [5, 13, 14, 30, 38], "length": [5, 13, 14, 24, 25, 30, 32, 38], "after": [5, 38, 40, 41], "block": [5, 25, 30], "size": [5, 24, 30, 38], "also": [5, 11, 12, 24, 30, 38, 41, 46, 47], "some": [5, 24, 30, 38, 41, 46, 47], "addit": [5, 30], "further": [5, 38, 47], "overwrite_cach": 5, "validation_split_percentag": [5, 46], "preprocessing_num_work": 5, "disable_group_text": 5, "demo_example_in_prompt": 5, "explanation_in_prompt": 5, "keep_linebreak": 5, "prompt_structur": [5, 27, 41, 42], "function": [5, 11, 12, 19, 28, 30, 45, 46, 47], "help": [5, 38, 46, 47], "messag": [5, 6, 7, 30], "each": [5, 30, 40, 46], "hint": [5, 6, 7], "metadata": [5, 30], "inform": [5, 6, 7, 24, 30, 46, 47], "about": [5, 30, 38, 45, 46, 47], "group_texts_batch_s": 5, "test_fil": 5, "finetunerargu": [5, 25], "base": [5, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 38, 45, 46, 47], "adapt": [5, 13, 14, 30, 47], "eval_dataset_path": 5, "evaluatorargu": [5, 24], "local_rank": [5, 28], "For": [5, 30, 38, 40, 43, 46, 47], "distribut": [5, 30], "random_shuffl": [5, 32], "use_wandb": [5, 24], "random_se": 5, "output_dir": [5, 30, 42], "mixed_precis": 5, "choic": [5, 32, 38], "bf16": 5, "fp16": 5, "mix": 5, "precis": 5, "deepspe": [5, 13, 14, 30, 41, 42, 44], "json": [5, 6, 7, 30, 32, 40, 41, 42, 44, 46], "e": [5, 28, 30, 32, 41, 47], "g": [5, 30], "ds_config": [5, 13, 14, 41, 42], "alreadi": [5, 30, 38, 46], "dict": [5, 6, 7, 30], "answer_typ": [5, 24, 32, 41, 42], "evaluate_block_s": 5, "metric": [5, 24, 30, 41], "inference_batch_size_per_devic": 5, "use_accelerator_for_evalu": 5, "inferencerargu": [5, 27], "devic": [5, 13, 14, 30], "do_sampl": 5, "raftalignerargu": [5, 28], "raft": [5, 43], "align": [5, 21, 28, 43], "output_reward_path": [5, 28], "output_min_length": [5, 28], "output_max_length": [5, 28], "num_raft_iter": 5, "raft_batch_s": 5, "top_reward_percentag": 5, "benchmarkingargu": 5, "lm_evaluation_metr": 5, "pipeline_argument_map": 5, "autoargu": [5, 44], "choos": [5, 30, 38, 46], "get_pipeline_args_class": [5, 44], "python": [6, 7, 38, 41, 42, 47], "code": [6, 7, 30, 38], "method": [6, 7, 13, 14, 24, 30, 38, 47], "manipul": [6, 7], "backend": [6, 7, 13, 14, 30], "hug": [6, 7, 40], "face": [6, 7], "dictionari": [6, 7, 24, 25, 30], "retriev": [6, 7], "dataset_typ": 6, "text_onli": [6, 19, 40, 41, 45, 46], "text2text": [6, 41, 43], "float_onli": [6, 45], "key_typ": 6, "key_inst": 6, "instanc": [6, 7, 13, 14, 19, 24, 25, 30, 38, 40, 45, 46, 47], "data_arg": [6, 7, 20, 24, 25, 27, 28, 44], "kwarg": [6, 7, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23, 25, 28, 30], "object": [6, 7, 19, 24, 25, 27, 28, 30], "given": [6, 7, 19, 24, 25, 27, 28, 30, 38, 41, 45, 46], "requir": [6, 7, 24, 25, 27, 28, 38, 46, 47], "posit": [6, 7, 13, 14, 19, 25, 28, 38, 45, 46, 47], "keyword": [6, 7, 13, 14, 19, 25, 28, 30], "_check_data_format": [6, 7], "check": [6, 7, 30, 38], "structur": [6, 7, 46], "match": [6, 7, 38], "rais": [6, 7, 30], "from_dict": [6, 7], "dict_obj": [6, 7], "return": [6, 7, 13, 14, 20, 24, 25, 27, 28, 30, 32, 38, 45, 46], "format": [6, 7, 43], "key_1": [6, 7, 40], "value_1": [6, 7, 40], "key_2": [6, 7, 40], "2": [6, 7, 28, 38, 40, 43, 44, 47], "value_2": [6, 7, 40], "self": [6, 7, 30, 33, 35], "classmethod": [6, 7, 9, 20], "create_from_dict": [6, 7, 45], "to_dict": [6, 7, 45], "get_backend": [6, 7], "get_backend_dataset": [6, 7], "backend_dataset": [6, 7], "get_fingerprint": [6, 7], "fingerprint": [6, 7], "which": [6, 7, 13, 14, 21, 23, 24, 30, 38, 40, 45, 46, 47], "control": [6, 7, 30], "get_data_arg": [6, 7], "get_typ": [6, 7], "internal_vers": 8, "__version__": [8, 37], "get": [9, 19, 28, 30, 38, 41, 42, 44, 46], "correct": 9, "automodel": 9, "get_model": 9, "model_arg": [9, 13, 14, 19, 20, 24, 25, 27, 28, 44], "basemodel": [10, 11, 12, 18, 28], "abc": [10, 11, 12, 17, 18, 22], "helper": [10, 11, 12, 17, 18, 22, 30], "standard": [10, 11, 12, 17, 18, 22], "wai": [10, 11, 12, 17, 18, 22, 30, 38, 40, 41, 42, 46], "inherit": [10, 11, 12, 17, 18, 22, 30], "one": [11, 12, 30, 38, 41, 44, 45, 46], "line": [11, 12, 38], "summari": [11, 12, 30], "program": [11, 12, 32], "termin": [11, 12], "period": [11, 12, 38], "leav": [11, 12, 38], "blank": [11, 12], "rest": [11, 12], "docstr": [11, 12], "should": [11, 12, 30, 38, 46], "overal": [11, 12, 13, 14, 47], "descript": [11, 12, 30], "mai": [11, 12, 30, 38, 41, 46], "brief": [11, 12], "export": [11, 12], "usag": [11, 12, 38], "typic": [11, 12, 38, 46], "foo": [11, 12], "classfoo": [11, 12], "bar": [11, 12], "functionbar": [11, 12], "decodermodel": [11, 13], "encoderdecodermodel": [12, 14], "call": [13, 14, 30, 38], "hfdecodermodel": [13, 14, 24], "wrapper": [13, 14, 30], "around": [13, 14, 38], "ha": [13, 14, 24, 30, 38, 40, 45], "__init__": [13, 14], "ar": [13, 14, 30, 38, 40, 41, 42, 46, 47], "fine": [13, 14, 30, 46, 47], "take": [13, 14, 24, 28, 30], "tune_strategi": [13, 14], "attent": [13, 14], "mask": [13, 14], "fed": [13, 14, 30], "support": [13, 14, 41, 42, 43, 45], "normal": [13, 14, 24, 38], "allow": [13, 14, 30, 38, 47], "howev": [13, 14, 38, 42, 47], "strategi": [13, 14], "yet": [13, 14], "implement": [13, 14, 30, 38, 41], "conveni": [13, 14, 38, 47], "variou": [13, 14, 30, 40, 47], "nlp": [13, 14, 38], "classif": [13, 14, 30], "question": [13, 14, 28, 38, 40], "answer": [13, 14, 32, 38, 40, 41, 46], "logger": [13, 14, 25, 28, 30], "models_support_flash_attent": 13, "llamaforcausallm": 13, "gptneoforcausallm": 13, "gpu": [13, 14, 30], "use_acceler": [13, 14], "revis": [13, 14, 19], "etc": [13, 14, 19, 30, 38, 47], "configu": [13, 14], "add_special_token": 13, "true": [13, 24, 25, 30, 32, 46], "full": [13, 14, 38, 46, 47], "tokenized_dataset": [13, 14, 25, 44], "without": [13, 30, 38, 46], "ani": [13, 30, 38, 46, 47], "lead": [13, 38, 45], "trail": 13, "special": [13, 47], "thei": [13, 30, 38, 40, 46], "begin": 13, "Of": 13, "sentenc": [13, 38], "end": [13, 30, 45], "encod": [13, 14, 24, 40], "union": [13, 14, 30], "perform": [13, 14, 24, 25, 27, 28, 30, 45, 46, 47], "process": [13, 14, 24, 25, 27, 28, 30, 38, 43, 44, 45, 46, 47], "output": [13, 14, 24, 28, 30, 32, 38, 40], "hello": 13, "world": [13, 38, 45], "101": [13, 38], "7592": 13, "1010": 13, "2088": 13, "102": 13, "batch": [13, 24, 30, 32, 35, 46], "input_id": [13, 46], "attention_mask": [13, 33, 35, 46], "token_type_id": 13, "tensor": [13, 30, 35], "decod": [13, 14, 24, 32, 40], "singl": [13, 30, 38, 40, 46], "prompt": [13, 14, 28, 40, 46, 47], "merge_lora_weight": [13, 14], "save": [13, 14, 30, 42, 47], "dir": [13, 14, 41], "save_full_model": [13, 14], "get_max_length": [13, 14, 44], "max": [13, 14, 24], "accept": [13, 14, 19, 24, 30, 40], "term": [13, 14, 38], "get_token": [13, 14], "get_backend_model": [13, 14], "hfencoderdecodermodel": 14, "abstract": [14, 21, 23], "regress": [18, 19], "regressionmodel": [18, 19, 28], "textregressionmodel": 19, "register_inference_funct": [19, 45], "inference_func": 19, "regist": [19, 45], "result": [19, 38, 45, 47], "onli": [19, 30, 38, 40, 41, 44, 46, 47], "its": [20, 30, 38, 47], "pipeline_map": 20, "autopipelin": [20, 44], "design": [20, 47], "get_pipelin": [20, 44], "pipeline_nam": [20, 44], "pipeline_arg": [20, 44], "basetun": [21, 23, 25], "subclass": [21, 23, 30], "basepipelin": [21, 22, 23, 24, 27], "basealign": [21, 28], "_check_if_align": 21, "reward_model": [21, 28, 45], "_check_if_tun": 23, "packag": [24, 43, 47], "constructor": 24, "three": [24, 38, 40, 46], "relat": [24, 46, 47], "evaluator_arg": 24, "other": [24, 30, 38, 46, 47], "two": [24, 30, 38, 41, 46], "create_dataload": [24, 27], "test": [24, 30, 38, 40, 42, 46, 47], "loader": 24, "iter": [24, 28, 30], "over": [24, 38, 40, 46], "mini": 24, "Then": [24, 42, 46], "write": [24, 38], "log": [24, 30, 38, 41], "consol": 24, "bias": [24, 45], "_match": 24, "predicted_answ": 24, "groundtruth": 24, "accuraci": [24, 38, 46, 47], "verbos": 24, "tunablemodel": [24, 25, 27, 44], "_evaluate_acc_with_acceler": 24, "_evaluate_acc_with_deepspe": 24, "_evaluate_ppl": 24, "_evaluate_nl": 24, "neg": [24, 38, 41, 46, 47], "likelihood": [24, 38, 41], "nll": [24, 38, 43], "n": [24, 38, 41, 47], "sum_": 24, "j": [24, 46], "w_i": 24, "ln": 24, "p": 24, "w_": 24, "context_window": 24, "sampl": [24, 30, 38, 40, 45, 46], "th": 24, "here": [24, 30, 38, 46], "start": [24, 30, 46], "p_": 24, "window_length": 24, "finetuner_arg": 25, "group_text": [25, 44], "model_max_length": [25, 44], "group": [25, 30, 44], "togeth": [25, 30], "form": [25, 30], "transform_dataset_in_plac": 25, "rstrip_partial_utf8": 27, "inferencer_arg": 27, "max_new_token": 27, "100": [27, 30, 46], "temperatur": 27, "output_dataset": 27, "stream_infer": 27, "context": [27, 30, 38], "token_per_step": 27, "end_str": 27, "input_dataset": 27, "raftalign": 28, "aligner_arg": 28, "raft_aligner_arg": 28, "_initialize_train": 28, "training_arg": [28, 30], "trainer": [28, 30], "_load_dataset": 28, "selected_dataset": 28, "prepar": [28, 30, 41, 46, 47], "everi": [28, 30], "_load_input_dataset": 28, "dataload": [28, 30, 32], "torch": [28, 30, 32, 35], "_get_batch_dataset_top": 28, "batch_input": 28, "alpha": 28, "iter_id": 28, "16": 28, "48": 28, "infer_batch_s": 28, "8": [28, 38, 47], "generation_kwarg": 28, "feed": [28, 30], "reward": [28, 43], "_is_native_cpu_amp_avail": 30, "default_callback": 30, "default_progress_callback": 30, "is_sagemaker_mp_post_1_10": 30, "skip_first_batch": 30, "training_args_nam": 30, "bin": 30, "trainer_state_nam": 30, "trainer_st": 30, "optimizer_nam": 30, "optim": 30, "pt": 30, "scheduler_nam": 30, "schedul": 30, "scaler_nam": 30, "scaler": 30, "rafttrain": 30, "modeling_util": 30, "pretrainedmodel": 30, "nn": [30, 46], "data_col": 30, "datacol": 30, "train_dataset": [30, 46], "eval_dataset": [30, 46], "tokenization_utils_bas": 30, "pretrainedtokenizerbas": 30, "model_init": 30, "callabl": 30, "compute_metr": 30, "trainer_util": 30, "evalpredict": 30, "callback": 30, "trainer_callback": 30, "trainercallback": 30, "lr_schedul": 30, "lambdalr": 30, "preprocess_logits_for_metr": 30, "featur": [30, 38], "complet": [30, 47], "eval": [30, 46], "loop": 30, "pytorch": 30, "predict": [30, 38], "must": [30, 44, 47], "tip": 30, "work": [30, 38, 45, 46], "you": [30, 38, 41, 42, 46, 47], "still": [30, 38, 46, 47], "your": [30, 43, 45, 46], "own": [30, 38, 40, 41, 45, 46], "long": [30, 38, 40], "same": [30, 46], "tweak": 30, "Will": 30, "basic": 30, "tmp_trainer": 30, "current": [30, 38, 40, 41], "element": [30, 38, 47], "default_data_col": 30, "datacollatorwithpad": 30, "otherwis": 30, "iterabledataset": 30, "column": 30, "forward": [30, 33, 35], "remov": 30, "note": [30, 38, 41, 47], "random": [30, 32], "fashion": 30, "either": 30, "intern": [30, 38], "ident": 30, "all": [30, 38, 42, 46, 47], "manual": [30, 38], "seed": [30, 32], "epoch": [30, 38], "have": [30, 38, 40, 41, 42, 45, 46, 47], "set_epoch": 30, "rng": 30, "prepend": 30, "kei": [30, 33, 38, 40, 41, 46], "preprocess": [30, 46], "pad": 30, "along": 30, "make": [30, 38, 41, 46, 47], "easier": 30, "rerun": 30, "interrupt": 30, "reus": 30, "instanti": 30, "new": [30, 38, 41, 46, 47], "zero": 30, "optuna": 30, "rai": 30, "sigopt": 30, "trial": [30, 38, 46], "abl": [30, 38, 46], "architectur": 30, "accord": [30, 38], "hyper": 30, "layer": 30, "count": [30, 38], "inner": 30, "dropout": 30, "probabl": [30, 38, 46], "comput": 30, "add": [30, 41], "those": [30, 38], "detail": [30, 38, 41, 43, 46], "want": [30, 41, 46], "remove_callback": 30, "adamw": 30, "get_linear_schedule_with_warmup": 30, "logit": 30, "right": [30, 38], "befor": [30, 47], "them": [30, 38, 41, 42, 46, 47], "step": [30, 41, 43], "label": [30, 38, 46], "onc": 30, "desir": [30, 46], "modif": 30, "made": [30, 38, 46], "reflect": [30, 38], "receiv": 30, "second": [30, 42], "doe": [30, 38, 47], "alwai": [30, 38, 46], "point": 30, "core": 30, "model_wrap": 30, "most": [30, 38, 40, 46], "extern": [30, 38], "case": [30, 38, 42, 46], "more": [30, 38, 45, 46, 47], "wrap": 30, "origin": [30, 38, 42, 46], "again": 30, "distributeddataparallel": 30, "hasn": 30, "t": [30, 38, 46], "been": [30, 38], "is_model_parallel": 30, "switch": [30, 46], "parallel": 30, "mean": [30, 38, 46], "split": [30, 46], "place_model_on_devic": 30, "place": [30, 46], "overridden": 30, "is_in_train": 30, "while": [30, 38, 47], "add_callback": 30, "In": [30, 38, 41, 42, 45, 46], "member": 30, "pop_callback": 30, "found": [30, 38, 47], "error": 30, "pop": 30, "_move_model_to_devic": 30, "_set_signature_columns_if_need": 30, "_remove_unused_column": 30, "_get_collator_with_removed_column": 30, "collat": 30, "unus": 30, "_get_train_sampl": 30, "sampler": 30, "get_train_dataload": 30, "__len__": 30, "inject": 30, "behavior": 30, "_get_eval_sampl": 30, "get_eval_dataload": 30, "get_test_dataload": 30, "test_dataset": 30, "create_optimizer_and_schedul": 30, "num_training_step": 30, "setup": [30, 43], "learn": [30, 45, 46, 47], "rate": 30, "we": [30, 38, 40, 41, 43, 44, 45, 46, 47], "reason": [30, 46], "well": [30, 38, 45, 47], "someth": [30, 38, 46], "els": [30, 44, 46], "init": 30, "through": [30, 38], "create_optim": 30, "create_schedul": 30, "static": 30, "get_optimizer_cls_and_kwarg": 30, "session": 30, "up": [30, 38, 46], "do": [30, 38, 46, 47], "num_exampl": 30, "access": [30, 38, 42, 47], "exist": 30, "estim": 30, "best": [30, 38, 45, 46], "_hp_search_setup": 30, "hp": 30, "search": [30, 47], "_report_to_hp_search": 30, "_tune_save_checkpoint": 30, "call_model_init": 30, "torch_jit_model_ev": 30, "ipex_optimize_model": 30, "float32": 30, "_wrap_model": 30, "resume_from_checkpoint": 30, "ignore_keys_for_ev": 30, "is_first_tim": 30, "main": [30, 41, 44, 47], "entri": 30, "local": [30, 38], "previou": [30, 45, 46], "equal": [30, 38], "last": [30, 46], "present": 30, "resum": 30, "state": [30, 38], "hyperparamet": 30, "ignor": 30, "gather": 30, "dure": [30, 38], "hide": [30, 46], "deprec": 30, "_one_train": 30, "batch_siz": [30, 32], "_inner_training_loop": 30, "serv": [30, 38, 47], "time": [30, 35, 38, 46], "updat": [30, 46], "_get_output_dir": 30, "_load_from_checkpoint": 30, "_load_best_model": 30, "_issue_warnings_after_load": 30, "load_result": 30, "_maybe_log_save_evalu": 30, "tr_loss": 30, "_load_rng_stat": 30, "_save_checkpoint": 30, "_load_optimizer_and_schedul": 30, "hyperparameter_search": 30, "hp_space": 30, "compute_object": 30, "n_trial": 30, "20": [30, 38], "direct": [30, 47], "minim": 30, "hpsearchbackend": 30, "hp_name": 30, "bestrun": 30, "launch": 30, "quantiti": 30, "determin": [30, 38], "loss": [30, 46], "sum": 30, "warn": 30, "To": [30, 40, 45, 46, 47], "need": [30, 38, 41, 42, 45, 46, 47], "reiniti": 30, "incompat": 30, "so": [30, 38, 45, 46, 47], "space": [30, 46], "default_hp_space_optuna": 30, "default_hp_space_rai": 30, "default_hp_space_sigopt": 30, "depend": [30, 38, 46], "maxim": [30, 47], "default_compute_object": 30, "greater": [30, 38], "lower": [30, 38], "pick": 30, "valid": 30, "training_util": 30, "instal": [30, 41], "create_studi": 30, "see": [30, 38, 46], "http": [30, 38, 41, 46, 47], "readthedoc": 30, "io": [30, 38, 47], "en": [30, 38], "stabl": 30, "refer": [30, 41, 43, 47], "studi": [30, 46], "html": [30, 38], "doc": 30, "latest": 30, "api_doc": 30, "execut": [30, 41], "app": 30, "com": [30, 38, 41, 47], "endpoint": 30, "experi": [30, 38, 45], "run_summari": 30, "watch": 30, "_prepare_input": 30, "nest": 30, "convert": [30, 32, 42], "handl": 30, "potenti": [30, 38], "compute_loss_context_manag": 30, "manag": 30, "autocast_smart_context_manag": 30, "cache_en": 30, "appropri": [30, 38, 46], "autocast": 30, "situat": [30, 38, 46], "training_step": 30, "target": [30, 47], "unpack": 30, "being": [30, 38, 46], "expect": [30, 38], "compute_loss": 30, "return_output": 30, "how": [30, 38, 43, 46], "By": [30, 42, 47], "is_local_process_zero": 30, "machin": [30, 47], "is_world_process_zero": 30, "global": 30, "go": [30, 38, 42], "save_model": 30, "_internal_cal": 30, "reload": 30, "from_pretrain": 30, "_save_tpu": 30, "_save": 30, "state_dict": 30, "store_flo": 30, "_sorted_checkpoint": 30, "checkpoint_prefix": 30, "prefix_checkpoint_dir": 30, "use_mtim": 30, "_rotate_checkpoint": 30, "ignore_kei": 30, "metric_key_prefix": 30, "respons": [30, 32, 38, 45, 46, 47], "wish": 30, "lst": 30, "prefix": [30, 46], "bleu": 30, "eval_bleu": 30, "come": [30, 38], "predictionoutput": 30, "like": [30, 38, 41, 46, 47], "test_bleu": 30, "becaus": [30, 38], "re": [30, 46], "dynam": 30, "concaten": [30, 38], "arrai": [30, 38], "index": [30, 47], "namedtupl": 30, "follow": [30, 40, 41, 46, 47], "np": 30, "ndarrai": 30, "label_id": 30, "evaluation_loop": 30, "prediction_loss_onli": 30, "evalloopoutput": 30, "share": [30, 45], "both": [30, 38, 45, 47], "_nested_gath": 30, "numpi": [30, 32], "_pad_across_process": 30, "pad_index": 30, "recurs": [30, 38], "safe": [30, 38, 46], "prediction_step": 30, "floating_point_op": 30, "oper": 30, "backward": 30, "anoth": [30, 38], "init_git_repo": 30, "at_init": 30, "git": [30, 41, 47], "repo": [30, 41], "hub_model_id": 30, "overwrite_output_dir": 30, "might": [30, 46], "wipe": 30, "out": [30, 38, 46, 47], "create_model_card": 30, "licens": [30, 38], "model_nam": [30, 41], "finetuned_from": 30, "dataset_tag": 30, "dataset_arg": 30, "draft": 30, "card": 30, "avail": [30, 38, 40, 41, 47], "applic": [30, 38, 47], "hub": [30, 38], "One": [30, 38], "identifi": 30, "_push_from_checkpoint": 30, "checkpoint_fold": 30, "push_to_hub": 30, "commit_messag": 30, "upload": 30, "push": 30, "finish": [30, 41], "url": [30, 47], "repositori": [30, 38, 47], "track": 30, "progress": 30, "prediction_loop": 30, "_gather_and_numpifi": 30, "_add_sm_patterns_to_gitignor": 30, "sagemak": 30, "pattern": 30, "gitignor": 30, "commonli": [31, 38, 47], "text_only_dataset_descript": 31, "text_only_dataset_detail": 31, "text2text_dataset_descript": 31, "text2text_dataset_detail": 31, "float_only_dataset_descript": 31, "text_only_dataset_long_descrit": 31, "text2text_dataset_long_descrit": 31, "dataset_description_map": 31, "instance_fields_map": 31, "set_random_se": 32, "cuda": 32, "load_data": 32, "file_nam": 32, "len": [32, 38, 44, 46], "batchliz": 32, "shuffl": 32, "answer_extract": 32, "funtion": 32, "plain": 32, "b": [32, 41], "c": [32, 38], "d": [32, 38, 46], "mutipl": 32, "qa": [32, 38], "_attn": 33, "queri": 33, "head_mask": 33, "hidden_st": [33, 35], "layer_past": 33, "use_cach": [33, 35], "output_attent": [33, 35], "replace_gpt_neo_attn_with_flash_attn": 33, "position_id": 35, "past_key_valu": 35, "shape": 35, "x": [35, 38, 46], "channel": 35, "bsz": 35, "q_len": 35, "_prepare_decoder_attention_mask": 35, "input_shap": 35, "inputs_emb": 35, "past_key_values_length": 35, "replace_llama_attn_with_flash_attn": 35, "9": [38, 41, 47], "style": 38, "larg": [38, 45, 47], "huge": 38, "challeng": [38, 45, 46], "sinc": [38, 40], "breakthrough": 38, "chatgpt": [38, 47], "On": 38, "hand": [38, 47], "research": 38, "engin": [38, 40], "reliabl": [38, 47], "compar": [38, 46, 47], "decid": [38, 41], "certain": [38, 46], "scenario": [38, 45], "monitor": 38, "avoid": 38, "issu": [38, 42, 45, 47], "forget": 38, "recent": 38, "vicuna": 38, "introduc": [38, 47], "comparison": 38, "human": [38, 41, 45, 46, 47], "k": [38, 46], "chatbot": [38, 45], "arena": 38, "pioneer": 38, "invok": 38, "gpt": [38, 46, 47], "4": [38, 40, 47], "expens": 38, "neither": 38, "scalabl": [38, 47], "nor": 38, "articl": 38, "cheap": 38, "easi": [38, 46], "aspect": 38, "everyon": 38, "commun": [38, 47], "toolkit": [38, 47], "our": [38, 40, 41, 42, 43, 44, 45, 47], "correspond": [38, 40], "corpu": 38, "itself": 38, "abil": [38, 47], "multi": 38, "round": 38, "convers": 38, "math": 38, "problem": [38, 43, 46], "solv": 38, "role": 38, "plai": 38, "corpora": 38, "quantit": 38, "idea": [38, 46], "behind": 38, "correl": 38, "essai": 38, "understand": [38, 47], "just": [38, 46], "chess": 38, "master": 38, "memor": 38, "endgam": 38, "chessboard": 38, "besid": 38, "similar": [38, 42], "ppl": 38, "nevertheless": 38, "intrins": 38, "induc": 38, "unfair": [38, 45], "between": 38, "smaller": 38, "vocabulari": 38, "inher": 38, "longer": 38, "level": [38, 47], "thu": 38, "instead": 38, "advantag": 38, "involv": [38, 46], "As": [38, 40, 46], "good": [38, 42, 46], "experiment": 38, "find": [38, 46], "tabl": [38, 41], "tradit": 38, "winogrand": 38, "boolq": 38, "arc_": 38, "hellaswag": 38, "piqa": 38, "obqa": 38, "arc_c": 38, "averag": [38, 47], "bloom": [38, 47], "3b": [38, 46], "58": [38, 46, 47], "7": [38, 47], "61": [38, 47], "6": [38, 47], "59": [38, 47], "5": [38, 46, 47], "52": [38, 46], "70": [38, 47], "42": 38, "30": [38, 47], "53": 38, "1b": 38, "64": [38, 46, 47], "62": 38, "65": [38, 46, 47], "73": [38, 47], "35": [38, 47], "33": 38, "56": [38, 47], "3": [38, 40, 41, 47], "opt": [38, 47], "9b": 38, "66": [38, 47], "67": [38, 47], "76": 38, "37": [38, 47], "34": 38, "13b": 38, "69": [38, 46, 47], "39": [38, 47], "llama": [38, 43, 45, 46, 47], "7b": [38, 42, 45, 46, 47], "78": [38, 47], "41": 38, "68": [38, 47], "74": [38, 47], "79": [38, 46], "44": [38, 47], "86": 38, "228": 38, "245": 38, "134": 38, "135": 38, "85": [38, 47], "215": 38, "81": 38, "237": 38, "130": 38, "96": 38, "129": 38, "200": 38, "224": 38, "125": 38, "124": 38, "82": 38, "198": 38, "220": 38, "97": 38, "123": 38, "167": 38, "71": [38, 46], "214": 38, "121": 38, "113": 38, "153": 38, "207": 38, "119": 38, "57": [38, 47], "83": 38, "109": 38, "figur": 38, "abov": [38, 40, 46], "roughli": 38, "magnitud": 38, "gap": 38, "entail": 38, "section": 38, "comprehens": 38, "summar": 38, "due": [38, 42], "limit": 38, "demonstr": [38, 45, 47], "partial": 38, "sheet": 38, "0501": 38, "optimalscal": [38, 47], "github": [38, 41, 47], "task_guid": 38, "robin": 38, "popular": [38, 46], "try": [38, 46], "onlin": [38, 45], "demo": [38, 43], "especi": 38, "observ": [38, 47], "foundat": [38, 45, 47], "obtain": [38, 42, 45, 47], "gain": [38, 47], "achiev": [38, 47], "better": [38, 47], "en_multi_round_chat": 38, "en_singe_round_chat": 38, "188": 38, "213": 38, "164": 38, "181": 38, "172": 38, "163": 38, "184": 38, "173": 38, "155": 38, "175": 38, "165": 38, "150": 38, "170": 38, "160": 38, "146": 38, "qualit": 38, "turn": [38, 46], "effortlessli": 38, "slight": 38, "mistak": 38, "sometim": 38, "doesn": 38, "item": [38, 41], "correctli": [38, 46], "mexican": 38, "food": 38, "cuisin": 38, "recommend": [38, 46], "omit": 38, "r1": 38, "capit": 38, "usa": 38, "unit": 38, "washington": 38, "district": 38, "columbia": 38, "locat": 38, "east": 38, "coast": 38, "countri": 38, "northern": 38, "part": [38, 45], "maryland": 38, "georg": 38, "presid": 38, "feder": 38, "directli": [38, 41, 42, 47], "administ": 38, "govern": 38, "citi": 38, "home": [38, 46], "mani": [38, 46], "nation": 38, "landmark": 38, "white": 38, "hous": [38, 46], "capitol": 38, "build": [38, 46], "suprem": 38, "court": 38, "museum": 38, "monument": 38, "cultur": [38, 46], "institut": 38, "virginia": 38, "r2": 38, "divers": 38, "scene": 38, "restaur": 38, "american": 38, "classic": 38, "There": [38, 46], "dish": 38, "hamburg": 38, "hot": 38, "dog": 38, "appl": 38, "pie": 38, "seafood": 38, "chesapeak": 38, "bai": 38, "known": 38, "fresh": 38, "crab": 38, "cake": 38, "shrimp": 38, "oyster": 38, "ethnic": 38, "popul": 38, "chines": 38, "japanes": 38, "korean": 38, "barbecu": 38, "pull": 38, "pork": 38, "rib": 38, "brisket": 38, "donut": 38, "famou": 38, "happi": [38, 46], "shop": 38, "varieti": 38, "flavor": 38, "top": 38, "street": 38, "truck": 38, "stand": 38, "falafel": 38, "kebab": 38, "taco": 38, "These": 38, "few": [38, 47], "wide": [38, 47], "rang": [38, 46, 47], "visit": 38, "soul": 38, "southern": 38, "bold": 38, "hearti": 38, "portion": 38, "fri": 38, "chicken": 38, "collard": 38, "green": 38, "macaroni": 38, "chees": 38, "ethiopian": 38, "spici": 38, "injera": 38, "sourdough": 38, "flatbread": 38, "wat": 38, "veget": 38, "stew": 38, "kitfo": 38, "meat": 38, "pasta": 38, "bbq": 38, "thrive": 38, "slow": 38, "cook": 38, "side": 38, "spot": 38, "ben": 38, "chili": 38, "bowl": 38, "pete": 38, "vegetarian": 38, "smoke": 38, "barrel": 38, "diplomaci": 38, "culinari": 38, "indian": 38, "r3": 38, "fifth": 38, "sure": [38, 46], "mention": 38, "usual": 38, "flame": 38, "heat": [38, 46], "coal": 38, "often": [38, 45], "marin": 38, "sauc": 38, "coleslaw": 38, "bake": 38, "bean": 38, "corn": 38, "cob": 38, "pit": 38, "smokehous": 38, "joint": 38, "salt": 38, "sovereign": 38, "offer": 38, "delici": 38, "margarita": 38, "adam": 38, "morgan": 38, "authent": 38, "year": [38, 47], "al": 38, "pastor": 38, "grill": 38, "enchilada": 38, "fill": 38, "tortilla": 38, "chile": 38, "relleno": 38, "stuf": 38, "pepper": 38, "el": 38, "comal": 38, "cozi": 38, "littl": 38, "height": 38, "neighborhood": 38, "mole": 38, "rich": 38, "blend": 38, "spice": 38, "chocol": 38, "de": 38, "carnita": 38, "crispi": 38, "queso": 38, "casa": 38, "oaxaca": 38, "upscal": 38, "shaw": 38, "menu": 38, "modern": 38, "cevich": 38, "raw": [38, 40], "fish": 38, "lime": 38, "juic": 38, "negro": 38, "dark": 38, "nogada": 38, "poblano": 38, "walnut": 38, "honei": 38, "king": 38, "chain": 38, "area": [38, 47], "burrito": 38, "afford": [38, 46], "price": 38, "carn": 38, "asada": 38, "quesadilla": 38, "lo": 38, "No": 38, "small": 38, "casual": 38, "adobada": 38, "real": [38, 45], "histori": [38, 46], "collect": 38, "183": 38, "english": 38, "total": 38, "447": 38, "break": 38, "multipl": [38, 47], "pair": [38, 40, 41], "q1": 38, "a1": 38, "q2": 38, "a2": 38, "q3": 38, "a3": 38, "q": 38, "ouptut": 38, "common": [38, 40, 47], "sens": 38, "acquir": [38, 47], "factual": 38, "knowledg": [38, 47], "properli": 38, "regard": 38, "degrad": 38, "competit": 38, "arc_easi": 38, "60": [38, 47], "72": [38, 47], "38": 38, "55": [38, 47], "63": [38, 47], "77": 38, "40": [38, 47], "75": [38, 47], "254": 38, "89": 38, "266": 38, "147": 38, "106": 38, "219": 38, "258": 38, "151": 38, "105": 38, "141": 38, "95": 38, "88": 38, "262": 38, "149": 38, "140": 38, "240": 38, "139": 38, "surpris": 38, "actual": [38, 46], "consequ": [38, 45], "hallucin": 38, "tend": 38, "give": [38, 46], "plausibl": 38, "incorrect": 38, "irrelev": 38, "explan": 38, "phenomenon": [38, 46], "attempt": 38, "fit": 38, "suffer": 38, "less": 38, "conjectur": 38, "improv": [38, 46, 47], "brought": 38, "higher": 38, "qualiti": [38, 45], "sharegpt": 38, "900mb": 38, "wa": [38, 45], "600mb": 38, "suggest": 38, "stage": 38, "critic": 38, "monei": 38, "compet": [38, 47], "show": [38, 43, 46], "possess": 38, "friend": 38, "door": 38, "lock": 38, "smell": 38, "ga": 38, "window": 38, "quickli": 38, "possibl": 38, "fire": [38, 46], "depart": 38, "compani": 38, "flammabl": 38, "danger": 38, "even": 38, "deadli": 38, "ventil": 38, "could": [38, 46], "caus": [38, 46], "explos": 38, "escap": 38, "cannot": 38, "stai": 38, "calm": 38, "wait": 38, "arriv": 38, "injuri": 38, "damag": [38, 46, 47], "yourself": 38, "addition": [38, 46], "illeg": 38, "enter": 38, "properti": 38, "permiss": 38, "homeown": 38, "locksmith": 38, "assist": [38, 41, 46], "unabl": 38, "emerg": 38, "servic": 38, "polic": 38, "meantim": 38, "lighter": 38, "leak": 38, "evacu": 38, "immedi": 38, "inde": 38, "injur": 38, "bring": 38, "my": [38, 46], "pet": 38, "ferret": 38, "beauti": 38, "pacif": 38, "island": 38, "attend": 38, "icml": 38, "m": [38, 46], "sorri": 38, "am": 38, "awar": [38, 47], "polici": 38, "confer": 38, "would": [38, 46], "organ": [38, 46], "author": [38, 47], "procedur": [38, 45, 46], "permit": 38, "proper": 38, "carri": [38, 46], "diseas": 38, "peopl": [38, 46], "toxoplasmosi": 38, "salmonellosi": 38, "priorit": 38, "health": 38, "safeti": 38, "crowd": 38, "event": 38, "held": [38, 47], "hawaii": 38, "strictli": 38, "prohibit": 38, "carrier": 38, "rabi": 38, "viru": 38, "eleuth": [38, 41], "ai": [38, 46, 47], "lm": [38, 43], "har": [38, 41], "eleutherai": [38, 41, 46], "final": 38, "loyal": 38, "obei": 38, "ethic": [38, 45], "legal": [38, 47], "gpt4_en_instruct": 38, "alpaca": [38, 42], "222": 38, "211": 38, "206": 38, "180": 38, "quicksort": 38, "ye": [38, 46], "algorithm": [38, 43], "def": [38, 44, 45, 46], "arr": 38, "pivot": 38, "left": 38, "middl": 38, "partit": 38, "sub": 38, "than": [38, 46], "appli": [38, 40, 47], "sort": [38, 46], "unsort": 38, "complex": 38, "o": [38, 44], "although": [38, 46], "faster": 38, "practic": 38, "carefulli": 38, "chosen": [38, 41, 46], "subarrai": 38, "produc": 38, "synonym": 38, "word": 38, "down": 38, "advers": 38, "difficulti": 38, "hardship": 38, "troubl": [38, 46], "misfortun": 38, "hard": [38, 46], "unpleas": 38, "circumst": [38, 46], "connot": 38, "difficult": 38, "hostil": 38, "factor": 38, "enemi": 38, "natur": [38, 47], "disast": 38, "mild": 38, "inconveni": 38, "major": 38, "setback": 38, "distress": 38, "financi": 38, "bad": 38, "luck": 38, "ill": [38, 45], "fate": 38, "econom": 38, "social": 38, "struggl": 38, "oppress": 38, "afflict": 38, "calam": 38, "tribul": 38, "10": [38, 46], "condit": 38, "describ": 38, "impli": 38, "intens": 38, "battl": 38, "conflict": 38, "obstacl": 38, "injustic": 38, "proceed": 38, "persecut": [38, 46], "order": 38, "project": 38, "000": 38, "filter": [38, 46], "767": 38, "effect": [38, 47], "remain": 38, "too": 38, "nonsens": 38, "incomplet": 38, "domain": [38, 47], "chemistri": 38, "biologi": [38, 47], "fail": 38, "par": 38, "surpass": [38, 47], "now": [38, 42], "Its": [38, 40, 47], "essenti": 38, "lmsy": 38, "org": [38, 46], "benchmark": [39, 43], "open": [39, 41, 47], "llm": 39, "cd": [40, 41, 42, 45], "sh": [40, 41, 42, 45, 46], "strongli": 40, "encourag": [40, 45], "techniqu": [40, 47], "below": [40, 41, 47], "specifi": [40, 41], "path_to_dataset": 40, "data_1": 40, "data_2": 40, "another_data": 40, "shall": [40, 47], "four": 40, "key_3": 40, "key_4": 40, "value_3": 40, "interpret": 40, "sample_text_1": 40, "sample_text_2": 40, "sample_text_3": 40, "example_dataset": 40, "train_50": 40, "mostli": 40, "sample_input_1": 40, "sample_output_1": 40, "sample_input_2": 40, "sample_output_2": 40, "sample_input_3": 40, "sample_output_3": 40, "test_13": 40, "easili": [41, 47], "fork": 41, "clone": [41, 47], "usernam": 41, "checkout": 41, "conda": [41, 47], "y": [41, 47], "activ": [41, 47], "mpi4pi": [41, 47], "pip": [41, 47], "notic": 41, "put": 41, "mkdir": 41, "mv": 41, "py": [41, 42, 45, 46], "info": 41, "local_datset_group_map": 41, "local_datset_map": 41, "local_datset_answertype_map": 41, "combin": 41, "task_combin": 41, "task_1": 41, "task_2": 41, "rememb": 41, "separ": 41, "chang": 41, "tee": 41, "log_dir": 41, "err": 41, "integr": 41, "benchamrk": 41, "command": [41, 46, 47], "simpli": 41, "lm_eval_dataset_map": 41, "pleas": [41, 47], "exact": 41, "similarli": 41, "slightli": 42, "copyright": 42, "facebookresearch": 42, "offici": 42, "hf": 42, "convert_llama_weights_to_hf": 42, "input_dir": 42, "model_s": 42, "enjoi": [42, 46], "With": 42, "output_model": [42, 45], "run_evaluation_with_lora": 42, "cuda_visible_devic": 42, "diff": 42, "textonli": 43, "sft": 43, "introduct": 43, "supervis": [43, 45], "rank": [43, 46], "guid": [43, 46], "registr": 43, "sy": 44, "hfargumentpars": 44, "tunable_model": 44, "pars": 44, "pipelineargu": 44, "parser": 44, "argv": 44, "endswith": 44, "let": [44, 46], "parse_json_fil": 44, "json_fil": 44, "abspath": 44, "parse_args_into_dataclass": 44, "todo": 44, "done": [44, 45], "main_process_first": 44, "desc": 44, "lm_dataset": 44, "tuned_model": 44, "unsupervis": 45, "implicit": 45, "Such": 45, "low": 45, "substanti": 45, "therefor": [45, 47], "prefer": [45, 46], "becom": 45, "crucial": [45, 47], "ensur": 45, "behav": 45, "primarili": 45, "reli": [45, 47], "reinforc": [45, 46], "feedback": [45, 46], "rlhf": [45, 46], "overcom": 45, "rl": 45, "despit": [45, 47], "feasibl": 45, "ineffici": 45, "instabl": 45, "pose": 45, "signific": [45, 47], "urgent": 45, "streamlin": [45, 47], "enhanc": [45, 47], "propos": 45, "suffici": 45, "reject": [45, 46], "ones": 45, "construct": 45, "offlin": 45, "furthermor": 45, "gradient": 45, "free": 45, "black": 45, "box": 45, "movi": 45, "review": 45, "topic": 45, "interact": [45, 46], "bot": 45, "favorit": 45, "run_raft_align": 45, "llama7b": 45, "reward_of": 45, "reward_funct": 45, "text_dataset": 45, "data_dict": 45, "assert": 45, "text_list": 45, "reward_list": 45, "adjust": 46, "instructgpt": [46, 47], "paper": 46, "arxiv": 46, "ab": 46, "2203": 46, "02155": 46, "dahoa": 46, "hh": 46, "consist": 46, "particular": [46, 47], "112k": 46, "12": 46, "5k": 46, "what": 46, "kind": 46, "nois": 46, "did": 46, "dinosaur": 46, "didn": 46, "live": 46, "realli": 46, "sai": 46, "guess": 46, "lot": 46, "read": 46, "amount": 46, "imagin": 46, "cant": 46, "stuff": 46, "don": 46, "know": 46, "10k": 46, "12k": 46, "hh_rlhf": 46, "ad": 46, "post": 46, "illustr": 46, "bui": 46, "protect": 46, "cell": 46, "phone": 46, "pocket": 46, "purs": 46, "But": 46, "quick": 46, "harm": 46, "parent": 46, "screen": 46, "thing": 46, "off": 46, "won": 46, "anyth": 46, "replac": 46, "aren": 46, "thank": 46, "me": 46, "welcom": 46, "salam": 46, "witch": 46, "look": 46, "book": 46, "witchcraft": 46, "histor": 46, "salem": 46, "1692": 46, "interest": 46, "coloni": 46, "america": 46, "excel": 46, "religion": 46, "declin": 46, "magic": 46, "belief": 46, "sixteenth": 46, "seventeenth": 46, "centuri": 46, "england": 46, "keith": 46, "thoma": 46, "otherworld": 46, "anthropologi": 46, "superstit": 46, "jack": 46, "goodi": 46, "popish": 46, "plot": 46, "prelat": 46, "everett": 46, "edit": 46, "run_finetun": 46, "modifi": 46, "neo": 46, "project_dir": 46, "run_finetune_with_lora": 46, "fortun": 46, "former": 46, "heater": 46, "hazard": 46, "tell": 46, "fireplac": 46, "room": 46, "materi": 46, "feel": 46, "touch": 46, "fuel": 46, "surround": 46, "That": 46, "glad": 46, "teach": [46, 47], "kid": 46, "fort": 46, "Or": 46, "elabor": 46, "exactli": 46, "mayb": 46, "simplest": 46, "pile": 46, "furnitur": 46, "bit": 46, "taller": 46, "sturdier": 46, "fun": 46, "explor": 46, "run_reward_model": 46, "select": 46, "percentag": 46, "load_dataset": 46, "build_dataset": 46, "assum": [46, 47], "answer_posit": 46, "answer_neg": 46, "tokenized_po": 46, "tokenized_neg": 46, "chosen_input_id": 46, "chosen_attention_mask": 46, "rejected_input_id": 46, "rejected_attention_mask": 46, "data_fil": 46, "lambda": 46, "512": 46, "idx_gap": 46, "logsigmoid": 46, "chosen_reward": 46, "rejected_reward": 46, "record": 46, "remark": [46, 47], "wandb": 46, "weixiong5237": 46, "t3uwm8yp": 46, "p2ju3r1a": 46, "rm": 46, "24": [46, 47], "8fc1rcf8": 46, "7oemwynu": 46, "10000": 46, "toolbox": 47, "friendli": 47, "speedi": 47, "entir": 47, "backbon": 47, "galactica": 47, "light": 47, "extrem": 47, "33b": 47, "25mb": 47, "storag": 47, "orient": 47, "whole": 47, "expans": 47, "except": 47, "capac": 47, "attain": 47, "intellig": 47, "convent": 47, "grow": 47, "cater": 47, "maintain": 47, "lightweight": 47, "thoughtfulli": 47, "tool": 47, "publicli": 47, "thoroughli": 47, "goal": 47, "profici": 47, "medicin": 47, "mathemat": 47, "subject": 47, "matter": 47, "medic": 47, "emphas": 47, "pubmedqa": 47, "medmcqa": 47, "medqa": 47, "usml": 47, "50": 47, "expert": 47, "87": 47, "90": 47, "175b": 47, "46": 47, "54": 47, "27": 47, "18": 47, "43": 47, "25": 47, "49": 47, "51": 47, "moreov": 47, "mmlu": 47, "verifi": 47, "robust": 47, "anatomi": 47, "clinic": 47, "colleg": 47, "genet": 47, "profession": 47, "32": 47, "36": 47, "30b": 47, "26": 47, "23": 47, "120b": 47, "21": 47, "176b": 47, "29": 47, "gopher": 47, "280b": 47, "gpt3": 47, "constraint": 47, "unseen": 47, "incorpor": 47, "cue": 47, "relev": 47, "power": 47, "approach": 47, "unlock": 47, "product": 47, "jsonl": 47, "readm": 47, "blog": 47, "misc": 47, "kashun": 47, "titl": 47, "publish": 47, "journal": 47, "howpublish": 47, "aim": 47, "intend": 47, "li": 47, "sole": 47, "guarante": 47, "compon": 47, "risk": 47, "liabil": 47, "associ": 47, "commerci": 47, "technic": 47, "advic": 47, "indirect": 47, "incident": 47, "consequenti": 47, "improp": 47, "highlight": 47, "probabilist": 47, "seek": 47, "outcom": 47, "account": 47, "relianc": 47, "submit": 47}, "objects": {"": [[8, 0, 0, "-", "lmflow"]], "lmflow": [[8, 1, 1, "", "__version__"], [5, 0, 0, "-", "args"], [7, 0, 0, "-", "datasets"], [8, 1, 1, "", "internal_version"], [15, 0, 0, "-", "models"], [26, 0, 0, "-", "pipeline"], [36, 0, 0, "-", "utils"], [37, 0, 0, "-", "version"]], "lmflow.args": [[5, 2, 1, "", "AutoArguments"], [5, 2, 1, "", "BenchmarkingArguments"], [5, 2, 1, "", "DatasetArguments"], [5, 2, 1, "", "EvaluatorArguments"], [5, 2, 1, "", "FinetunerArguments"], [5, 2, 1, "", "InferencerArguments"], [5, 1, 1, "", "MODEL_CONFIG_CLASSES"], [5, 1, 1, "", "MODEL_TYPES"], [5, 2, 1, "", "ModelArguments"], [5, 1, 1, "", "PIPELINE_ARGUMENT_MAPPING"], [5, 2, 1, "", "RaftAlignerArguments"]], "lmflow.args.AutoArguments": [[5, 3, 1, "", "get_pipeline_args_class"]], "lmflow.args.BenchmarkingArguments": [[5, 4, 1, "", "dataset_name"], [5, 4, 1, "", "lm_evaluation_metric"]], "lmflow.args.DatasetArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "", "block_size"], [5, 4, 1, "", "customized_cache_dir"], [5, 4, 1, "", "dataset_config_name"], [5, 4, 1, "", "dataset_name"], [5, 4, 1, "", "dataset_path"], [5, 4, 1, "", "disable_group_texts"], [5, 4, 1, "", "group_texts_batch_size"], [5, 4, 1, "", "is_custom_dataset"], [5, 4, 1, "", "keep_linebreaks"], [5, 4, 1, "", "max_eval_samples"], [5, 4, 1, "", "max_train_samples"], [5, 4, 1, "", "overwrite_cache"], [5, 4, 1, "", "preprocessing_num_workers"], [5, 4, 1, "", "streaming"], [5, 4, 1, "", "test_file"], [5, 4, 1, "", "train_file"], [5, 4, 1, "", "validation_file"], [5, 4, 1, "", "validation_split_percentage"]], "lmflow.args.EvaluatorArguments": [[5, 4, 1, "", "answer_type"], [5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "evaluate_block_size"], [5, 4, 1, "", "inference_batch_size_per_device"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "metric"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "output_dir"], [5, 4, 1, "", "prompt_structure"], [5, 4, 1, "", "random_seed"], [5, 4, 1, "", "random_shuffle"], [5, 4, 1, "", "use_accelerator_for_evaluator"], [5, 4, 1, "", "use_wandb"]], "lmflow.args.FinetunerArguments": [[5, 4, 1, "", "eval_dataset_path"]], "lmflow.args.InferencerArguments": [[5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "device"], [5, 4, 1, "", "do_sample"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "random_seed"]], "lmflow.args.ModelArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "id0", "arch_type"], [5, 4, 1, "", "cache_dir"], [5, 4, 1, "", "config_name"], [5, 4, 1, "", "config_overrides"], [5, 4, 1, "", "lora_alpha"], [5, 4, 1, "", "lora_dropout"], [5, 4, 1, "", "lora_model_path"], [5, 4, 1, "", "lora_r"], [5, 4, 1, "", "lora_target_modules"], [5, 4, 1, "", "model_name_or_path"], [5, 4, 1, "", "model_revision"], [5, 4, 1, "", "model_type"], [5, 4, 1, "", "save_aggregated_lora"], [5, 4, 1, "", "tokenizer_name"], [5, 4, 1, "", "torch_dtype"], [5, 4, 1, "", "use_auth_token"], [5, 4, 1, "", "use_fast_tokenizer"], [5, 4, 1, "", "use_flash_attention"], [5, 4, 1, "", "use_lora"], [5, 4, 1, "", "use_ram_optimized_load"]], "lmflow.args.RaftAlignerArguments": [[5, 4, 1, "", "inference_batch_size_per_device"], [5, 4, 1, "", "num_raft_iteration"], [5, 4, 1, "", "output_max_length"], [5, 4, 1, "", "output_min_length"], [5, 4, 1, "", "output_reward_path"], [5, 4, 1, "", "raft_batch_size"], [5, 4, 1, "", "top_reward_percentage"]], "lmflow.datasets": [[7, 2, 1, "", "Dataset"], [6, 0, 0, "-", "dataset"]], "lmflow.datasets.Dataset": [[7, 3, 1, "", "_check_data_format"], [7, 3, 1, "", "create_from_dict"], [7, 3, 1, "", "from_dict"], [7, 3, 1, "", "get_backend"], [7, 3, 1, "", "get_backend_dataset"], [7, 3, 1, "", "get_data_args"], [7, 3, 1, "", "get_fingerprint"], [7, 3, 1, "", "get_type"], [7, 3, 1, "", "map"], [7, 3, 1, "", "to_dict"]], "lmflow.datasets.dataset": [[6, 1, 1, "", "DATASET_TYPES"], [6, 2, 1, "", "Dataset"], [6, 1, 1, "", "KEY_INSTANCES"], [6, 1, 1, "", "KEY_TYPE"]], "lmflow.datasets.dataset.Dataset": [[6, 3, 1, "", "_check_data_format"], [6, 3, 1, "", "create_from_dict"], [6, 3, 1, "", "from_dict"], [6, 3, 1, "", "get_backend"], [6, 3, 1, "", "get_backend_dataset"], [6, 3, 1, "", "get_data_args"], [6, 3, 1, "", "get_fingerprint"], [6, 3, 1, "", "get_type"], [6, 3, 1, "", "map"], [6, 3, 1, "", "to_dict"]], "lmflow.models": [[9, 0, 0, "-", "auto_model"], [10, 0, 0, "-", "base_model"], [11, 0, 0, "-", "decoder_model"], [12, 0, 0, "-", "encoder_decoder_model"], [13, 0, 0, "-", "hf_decoder_model"], [14, 0, 0, "-", "hf_encoder_decoder_model"], [16, 0, 0, "-", "interfaces"], [18, 0, 0, "-", "regression_model"], [19, 0, 0, "-", "text_regression_model"]], "lmflow.models.auto_model": [[9, 2, 1, "", "AutoModel"]], "lmflow.models.auto_model.AutoModel": [[9, 3, 1, "", "get_model"]], "lmflow.models.base_model": [[10, 2, 1, "", "BaseModel"]], "lmflow.models.decoder_model": [[11, 2, 1, "", "DecoderModel"]], "lmflow.models.encoder_decoder_model": [[12, 2, 1, "", "EncoderDecoderModel"]], "lmflow.models.hf_decoder_model": [[13, 2, 1, "", "HFDecoderModel"], [13, 1, 1, "", "MODELS_SUPPORT_FLASH_ATTENTION"], [13, 1, 1, "", "logger"]], "lmflow.models.hf_decoder_model.HFDecoderModel": [[13, 3, 1, "", "decode"], [13, 3, 1, "", "encode"], [13, 3, 1, "", "get_backend_model"], [13, 3, 1, "", "get_max_length"], [13, 3, 1, "", "get_tokenizer"], [13, 3, 1, "", "inference"], [13, 3, 1, "", "merge_lora_weights"], [13, 3, 1, "", "save"], [13, 3, 1, "", "tokenize"]], "lmflow.models.hf_encoder_decoder_model": [[14, 2, 1, "", "HFEncoderDecoderModel"], [14, 1, 1, "", "logger"]], "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel": [[14, 3, 1, "", "decode"], [14, 3, 1, "", "encode"], [14, 3, 1, "", "get_backend_model"], [14, 3, 1, "", "get_max_length"], [14, 3, 1, "", "get_tokenizer"], [14, 3, 1, "", "inference"], [14, 3, 1, "", "merge_lora_weights"], [14, 3, 1, "", "save"], [14, 3, 1, "", "tokenize"]], "lmflow.models.interfaces": [[17, 0, 0, "-", "tunable"]], "lmflow.models.interfaces.tunable": [[17, 2, 1, "", "Tunable"]], "lmflow.models.regression_model": [[18, 2, 1, "", "RegressionModel"]], "lmflow.models.text_regression_model": [[19, 2, 1, "", "TextRegressionModel"]], "lmflow.models.text_regression_model.TextRegressionModel": [[19, 3, 1, "", "inference"], [19, 3, 1, "", "register_inference_function"]], "lmflow.pipeline": [[20, 0, 0, "-", "auto_pipeline"], [21, 0, 0, "-", "base_aligner"], [22, 0, 0, "-", "base_pipeline"], [23, 0, 0, "-", "base_tuner"], [24, 0, 0, "-", "evaluator"], [25, 0, 0, "-", "finetuner"], [27, 0, 0, "-", "inferencer"], [28, 0, 0, "-", "raft_aligner"], [29, 0, 0, "-", "utils"]], "lmflow.pipeline.auto_pipeline": [[20, 2, 1, "", "AutoPipeline"], [20, 1, 1, "", "PIPELINE_MAPPING"]], "lmflow.pipeline.auto_pipeline.AutoPipeline": [[20, 3, 1, "", "get_pipeline"]], "lmflow.pipeline.base_aligner": [[21, 2, 1, "", "BaseAligner"]], "lmflow.pipeline.base_aligner.BaseAligner": [[21, 3, 1, "", "_check_if_alignable"], [21, 3, 1, "", "align"]], "lmflow.pipeline.base_pipeline": [[22, 2, 1, "", "BasePipeline"]], "lmflow.pipeline.base_tuner": [[23, 2, 1, "", "BaseTuner"]], "lmflow.pipeline.base_tuner.BaseTuner": [[23, 3, 1, "", "_check_if_tunable"], [23, 3, 1, "", "tune"]], "lmflow.pipeline.evaluator": [[24, 2, 1, "", "Evaluator"]], "lmflow.pipeline.evaluator.Evaluator": [[24, 3, 1, "", "_evaluate_acc_with_accelerator"], [24, 3, 1, "", "_evaluate_acc_with_deepspeed"], [24, 3, 1, "", "_evaluate_nll"], [24, 3, 1, "", "_evaluate_ppl"], [24, 3, 1, "", "_match"], [24, 3, 1, "", "create_dataloader"], [24, 3, 1, "", "evaluate"]], "lmflow.pipeline.finetuner": [[25, 2, 1, "", "Finetuner"], [25, 1, 1, "", "logger"]], "lmflow.pipeline.finetuner.Finetuner": [[25, 3, 1, "", "group_text"], [25, 3, 1, "", "tune"]], "lmflow.pipeline.inferencer": [[27, 2, 1, "", "Inferencer"], [27, 5, 1, "", "rstrip_partial_utf8"]], "lmflow.pipeline.inferencer.Inferencer": [[27, 3, 1, "", "create_dataloader"], [27, 3, 1, "", "inference"], [27, 3, 1, "", "stream_inference"]], "lmflow.pipeline.raft_aligner": [[28, 2, 1, "", "RaftAligner"], [28, 1, 1, "", "logger"]], "lmflow.pipeline.raft_aligner.RaftAligner": [[28, 3, 1, "", "_get_batch_dataset_top"], [28, 3, 1, "", "_initialize_trainer"], [28, 3, 1, "", "_load_dataset"], [28, 3, 1, "", "_load_input_dataset"], [28, 3, 1, "", "align"]], "lmflow.pipeline.utils": [[30, 0, 0, "-", "raft_trainer"]], "lmflow.pipeline.utils.raft_trainer": [[30, 1, 1, "", "DEFAULT_CALLBACKS"], [30, 1, 1, "id0", "DEFAULT_PROGRESS_CALLBACK"], [30, 1, 1, "", "IS_SAGEMAKER_MP_POST_1_10"], [30, 1, 1, "", "OPTIMIZER_NAME"], [30, 2, 1, "", "RaftTrainer"], [30, 1, 1, "", "SCALER_NAME"], [30, 1, 1, "", "SCHEDULER_NAME"], [30, 1, 1, "", "TRAINER_STATE_NAME"], [30, 1, 1, "", "TRAINING_ARGS_NAME"], [30, 1, 1, "", "_is_native_cpu_amp_available"], [30, 1, 1, "", "logger"], [30, 1, 1, "", "skip_first_batches"]], "lmflow.pipeline.utils.raft_trainer.RaftTrainer": [[30, 3, 1, "", "_add_sm_patterns_to_gitignore"], [30, 3, 1, "", "_gather_and_numpify"], [30, 3, 1, "", "_get_collator_with_removed_columns"], [30, 3, 1, "", "_get_eval_sampler"], [30, 3, 1, "", "_get_output_dir"], [30, 3, 1, "", "_get_train_sampler"], [30, 3, 1, "", "_hp_search_setup"], [30, 3, 1, "", "_inner_training_loop"], [30, 3, 1, "", "_issue_warnings_after_load"], [30, 3, 1, "", "_load_best_model"], [30, 3, 1, "", "_load_from_checkpoint"], [30, 3, 1, "", "_load_optimizer_and_scheduler"], [30, 3, 1, "", "_load_rng_state"], [30, 3, 1, "", "_maybe_log_save_evaluate"], [30, 3, 1, "", "_move_model_to_device"], [30, 3, 1, "", "_nested_gather"], [30, 3, 1, "", "_one_train"], [30, 3, 1, "", "_pad_across_processes"], [30, 3, 1, "", "_prepare_input"], [30, 3, 1, "", "_prepare_inputs"], [30, 3, 1, "", "_push_from_checkpoint"], [30, 3, 1, "", "_remove_unused_columns"], [30, 3, 1, "", "_report_to_hp_search"], [30, 3, 1, "", "_rotate_checkpoints"], [30, 3, 1, "", "_save"], [30, 3, 1, "", "_save_checkpoint"], [30, 3, 1, "", "_save_tpu"], [30, 3, 1, "", "_set_signature_columns_if_needed"], [30, 3, 1, "", "_sorted_checkpoints"], [30, 3, 1, "", "_tune_save_checkpoint"], [30, 3, 1, "", "_wrap_model"], [30, 3, 1, "", "add_callback"], [30, 3, 1, "", "autocast_smart_context_manager"], [30, 3, 1, "", "call_model_init"], [30, 3, 1, "", "compute_loss"], [30, 3, 1, "", "compute_loss_context_manager"], [30, 3, 1, "", "create_model_card"], [30, 3, 1, "", "create_optimizer"], [30, 3, 1, "", "create_optimizer_and_scheduler"], [30, 3, 1, "", "create_scheduler"], [30, 3, 1, "", "evaluate"], [30, 3, 1, "", "evaluation_loop"], [30, 3, 1, "", "floating_point_ops"], [30, 3, 1, "", "get_eval_dataloader"], [30, 3, 1, "", "get_optimizer_cls_and_kwargs"], [30, 3, 1, "", "get_test_dataloader"], [30, 3, 1, "", "get_train_dataloader"], [30, 3, 1, "", "hyperparameter_search"], [30, 3, 1, "", "init_git_repo"], [30, 3, 1, "", "ipex_optimize_model"], [30, 3, 1, "", "is_local_process_zero"], [30, 3, 1, "", "is_world_process_zero"], [30, 3, 1, "", "log"], [30, 3, 1, "", "num_examples"], [30, 3, 1, "", "pop_callback"], [30, 3, 1, "", "predict"], [30, 3, 1, "", "prediction_loop"], [30, 3, 1, "", "prediction_step"], [30, 3, 1, "", "push_to_hub"], [30, 3, 1, "", "remove_callback"], [30, 3, 1, "", "save_model"], [30, 3, 1, "", "store_flos"], [30, 3, 1, "", "torch_jit_model_eval"], [30, 3, 1, "", "train"], [30, 3, 1, "", "training_step"]], "lmflow.utils": [[31, 0, 0, "-", "constants"], [32, 0, 0, "-", "data_utils"], [34, 0, 0, "-", "flash_attention"]], "lmflow.utils.constants": [[31, 1, 1, "", "DATASET_DESCRIPTION_MAP"], [31, 1, 1, "", "FLOAT_ONLY_DATASET_DESCRIPTION"], [31, 1, 1, "", "INSTANCE_FIELDS_MAP"], [31, 1, 1, "", "TEXT2TEXT_DATASET_DESCRIPTION"], [31, 1, 1, "", "TEXT2TEXT_DATASET_DETAILS"], [31, 1, 1, "", "TEXT2TEXT_DATASET_LONG_DESCRITION"], [31, 1, 1, "", "TEXT_ONLY_DATASET_DESCRIPTION"], [31, 1, 1, "", "TEXT_ONLY_DATASET_DETAILS"], [31, 1, 1, "", "TEXT_ONLY_DATASET_LONG_DESCRITION"]], "lmflow.utils.data_utils": [[32, 5, 1, "", "answer_extraction"], [32, 5, 1, "", "batchlize"], [32, 5, 1, "", "load_data"], [32, 5, 1, "", "set_random_seed"]], "lmflow.utils.flash_attention": [[33, 0, 0, "-", "gpt_neo_flash_attention"], [35, 0, 0, "-", "llama_flash_attention"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[33, 5, 1, "", "_attn"], [33, 5, 1, "", "forward"], [33, 5, 1, "", "replace_gpt_neo_attn_with_flash_attn"]], "lmflow.utils.flash_attention.llama_flash_attention": [[35, 5, 1, "", "_prepare_decoder_attention_mask"], [35, 5, 1, "", "forward"], [35, 5, 1, "", "replace_llama_attn_with_flash_attn"]], "lmflow.version": [[37, 1, 1, "", "__version__"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:method", "4": "py:attribute", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"]}, "titleterms": {"contributor": 0, "changelog": 1, "version": [1, 37], "0": 1, "1": [1, 41, 46], "mar": 1, "28": 1, "2023": [1, 39], "about": 2, "lmflow": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 47], "arg": [3, 5], "api": 4, "refer": [4, 38], "modul": [5, 6, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 37], "content": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 37, 47], "class": [5, 6, 7, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30], "attribut": [5, 6, 13, 14, 20, 25, 28, 30], "dataset": [6, 7, 40, 41], "submodul": [7, 8, 15, 16, 26, 29, 34, 36], "packag": [7, 8], "subpackag": [8, 15, 26, 36], "model": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 46], "auto_model": 9, "base_model": 10, "decoder_model": 11, "encoder_decoder_model": 12, "hf_decoder_model": 13, "hf_encoder_decoder_model": 14, "interfac": [16, 17], "tunabl": 17, "regression_model": 18, "text_regression_model": 19, "pipelin": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "auto_pipelin": 20, "base_align": 21, "base_pipelin": 22, "base_tun": 23, "evalu": [24, 38, 41, 43], "finetun": [25, 43, 44, 45, 46], "inferenc": 27, "function": [27, 32, 33, 35], "raft_align": 28, "util": [29, 30, 31, 32, 33, 34, 35, 36], "raft_train": 30, "constant": 31, "data_util": 32, "flash_attent": [33, 34, 35], "gpt_neo_flash_attent": 33, "llama_flash_attent": 35, "benchmark": [38, 41], "an": 38, "automat": 38, "framework": 38, "open": 38, "sourc": 38, "llm": 38, "introduct": [38, 45, 46, 47], "metric": 38, "chat": 38, "perform": 38, "commonsens": 38, "instruct": [38, 47], "follow": 38, "conclus": 38, "blog": 39, "format": 40, "gener": 40, "support": [40, 47], "detail": 40, "textonli": 40, "text2text": 40, "guid": 41, "nll": 41, "task": [41, 47], "set": 41, "setup": 41, "creat": 41, "your": 41, "file": 41, "registr": 41, "2": [41, 46], "lm": 41, "checkpoint": [42, 47], "llama": 42, "exampl": [43, 46], "data": 43, "prepar": 43, "infer": 43, "reward": [45, 46], "rank": 45, "raft": 45, "algorithm": 45, "demo": 45, "custom": 45, "align": 45, "step": 46, "supervis": 46, "sft": 46, "featur": 47, "tune": 47, "instal": 47, "citat": 47, "disclaim": 47, "indic": 47, "tabl": 47}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Contributors": [[0, "contributors"]], "Changelog": [[1, "changelog"]], "Version 0.0.1 (Mar 28, 2023)": [[1, "version-0-0-1-mar-28-2023"]], "About": [[2, "about"]], "lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "API Reference": [[4, "api-reference"]], "Module Contents": [[5, "module-contents"], [6, "module-contents"], [9, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [27, "module-contents"], [28, "module-contents"], [30, "module-contents"], [31, "module-contents"], [32, "module-contents"], [33, "module-contents"], [35, "module-contents"], [37, "module-contents"]], "Classes": [[5, "classes"], [6, "classes"], [7, "classes"], [9, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [13, "classes"], [14, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [27, "classes"], [28, "classes"], [30, "classes"]], "Attributes": [[5, "attributes"], [6, "attributes"], [13, "attributes"], [14, "attributes"], [20, "attributes"], [25, "attributes"], [28, "attributes"], [30, "attributes"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "Submodules": [[7, "submodules"], [8, "submodules"], [15, "submodules"], [16, "submodules"], [26, "submodules"], [29, "submodules"], [34, "submodules"], [36, "submodules"]], "Package Contents": [[7, "package-contents"], [8, "package-contents"]], "lmflow": [[8, "module-lmflow"]], "Subpackages": [[8, "subpackages"], [15, "subpackages"], [26, "subpackages"], [36, "subpackages"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "lmflow.models.encoder_decoder_model": [[12, "module-lmflow.models.encoder_decoder_model"]], "lmflow.models.hf_decoder_model": [[13, "module-lmflow.models.hf_decoder_model"]], "lmflow.models.hf_encoder_decoder_model": [[14, "module-lmflow.models.hf_encoder_decoder_model"]], "lmflow.models": [[15, "module-lmflow.models"]], "lmflow.models.interfaces": [[16, "module-lmflow.models.interfaces"]], "lmflow.models.interfaces.tunable": [[17, "module-lmflow.models.interfaces.tunable"]], "lmflow.models.regression_model": [[18, "module-lmflow.models.regression_model"]], "lmflow.models.text_regression_model": [[19, "module-lmflow.models.text_regression_model"]], "lmflow.pipeline.auto_pipeline": [[20, "module-lmflow.pipeline.auto_pipeline"]], "lmflow.pipeline.base_aligner": [[21, "module-lmflow.pipeline.base_aligner"]], "lmflow.pipeline.base_pipeline": [[22, "module-lmflow.pipeline.base_pipeline"]], "lmflow.pipeline.base_tuner": [[23, "module-lmflow.pipeline.base_tuner"]], "lmflow.pipeline.evaluator": [[24, "module-lmflow.pipeline.evaluator"]], "lmflow.pipeline.finetuner": [[25, "module-lmflow.pipeline.finetuner"]], "lmflow.pipeline": [[26, "module-lmflow.pipeline"]], "lmflow.pipeline.inferencer": [[27, "module-lmflow.pipeline.inferencer"]], "Functions": [[27, "functions"], [32, "functions"], [33, "functions"], [35, "functions"]], "lmflow.pipeline.raft_aligner": [[28, "module-lmflow.pipeline.raft_aligner"]], "lmflow.pipeline.utils": [[29, "module-lmflow.pipeline.utils"]], "lmflow.pipeline.utils.raft_trainer": [[30, "module-lmflow.pipeline.utils.raft_trainer"]], "lmflow.utils.constants": [[31, "module-lmflow.utils.constants"]], "lmflow.utils.data_utils": [[32, "module-lmflow.utils.data_utils"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[33, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"]], "lmflow.utils.flash_attention": [[34, "module-lmflow.utils.flash_attention"]], "lmflow.utils.flash_attention.llama_flash_attention": [[35, "module-lmflow.utils.flash_attention.llama_flash_attention"]], "lmflow.utils": [[36, "module-lmflow.utils"]], "lmflow.version": [[37, "module-lmflow.version"]], "LMFlow Benchmark: An Automatic Evaluation Framework for Open-Source LLMs": [[38, "lmflow-benchmark-an-automatic-evaluation-framework-for-open-source-llms"]], "Introduction": [[38, "introduction"], [45, "introduction"], [46, "introduction"], [47, "introduction"]], "Metric": [[38, "metric"]], "Chat Performance": [[38, "chat-performance"]], "CommonSense Performance": [[38, "commonsense-performance"]], "Instruction Following": [[38, "instruction-following"]], "Conclusion": [[38, "conclusion"]], "References": [[38, "references"]], "Blogs": [[39, "blogs"]], "2023": [[39, "id1"]], "Dataset": [[40, "dataset"]], "Dataset Format in General": [[40, "dataset-format-in-general"]], "Supported Dataset and Detailed Formats": [[40, "supported-dataset-and-detailed-formats"]], "TextOnly": [[40, "textonly"]], "Text2Text": [[40, "text2text"]], "LMFlow Benchmark Guide": [[41, "lmflow-benchmark-guide"]], "1. NLL Task Setting": [[41, "nll-task-setting"]], "Setup": [[41, "setup"]], "Create Your Task Dataset File": [[41, "create-your-task-dataset-file"]], "Task Registration": [[41, "task-registration"]], "2. LM-Evaluation Task Setting": [[41, "lm-evaluation-task-setting"]], "Checkpoints": [[42, "checkpoints"], [47, "checkpoints"]], "LLaMA Checkpoint": [[42, "llama-checkpoint"]], "Examples": [[43, "examples"], [46, "examples"]], "Data preparation": [[43, "data-preparation"]], "Finetuning": [[43, "finetuning"]], "Inference": [[43, "inference"]], "Evaluation": [[43, "evaluation"]], "Finetune": [[44, "finetune"]], "Reward rAnked FineTuning (RAFT)": [[45, "reward-ranked-finetuning-raft"]], "Algorithm": [[45, "algorithm"]], "Demo": [[45, "demo"]], "Customized Alignments": [[45, "customized-alignments"]], "Reward Modeling": [[46, "reward-modeling"]], "Step 1 Supervised Finetuning (SFT)": [[46, "step-1-supervised-finetuning-sft"]], "Step 2 Reward Modeling": [[46, "step-2-reward-modeling"]], "LMFlow": [[47, "lmflow"]], "Features": [[47, "features"]], "Task Tuning": [[47, "task-tuning"]], "Instruction Tuning": [[47, "instruction-tuning"]], "Installation": [[47, "installation"]], "Content": [[47, "content"]], "Citation": [[47, "citation"]], "Disclaimer": [[47, "disclaimer"]], "Support": [[47, "support"]], "Indices and tables": [[47, "indices-and-tables"]]}, "indexentries": {"lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "module": [[3, "module-lmflow.args"], [5, "module-lmflow.args"], [6, "module-lmflow.datasets.dataset"], [7, "module-lmflow.datasets"], [8, "module-lmflow"], [9, "module-lmflow.models.auto_model"], [10, "module-lmflow.models.base_model"], [11, "module-lmflow.models.decoder_model"], [12, "module-lmflow.models.encoder_decoder_model"], [13, "module-lmflow.models.hf_decoder_model"], [14, "module-lmflow.models.hf_encoder_decoder_model"], [15, "module-lmflow.models"], [16, "module-lmflow.models.interfaces"], [17, "module-lmflow.models.interfaces.tunable"], [18, "module-lmflow.models.regression_model"], [19, "module-lmflow.models.text_regression_model"], [20, "module-lmflow.pipeline.auto_pipeline"], [21, "module-lmflow.pipeline.base_aligner"], [22, "module-lmflow.pipeline.base_pipeline"], [23, "module-lmflow.pipeline.base_tuner"], [24, "module-lmflow.pipeline.evaluator"], [25, "module-lmflow.pipeline.finetuner"], [26, "module-lmflow.pipeline"], [27, "module-lmflow.pipeline.inferencer"], [28, "module-lmflow.pipeline.raft_aligner"], [29, "module-lmflow.pipeline.utils"], [30, "module-lmflow.pipeline.utils.raft_trainer"], [31, "module-lmflow.utils.constants"], [32, "module-lmflow.utils.data_utils"], [33, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"], [34, "module-lmflow.utils.flash_attention"], [35, "module-lmflow.utils.flash_attention.llama_flash_attention"], [36, "module-lmflow.utils"], [37, "module-lmflow.version"]], "autoarguments (class in lmflow.args)": [[5, "lmflow.args.AutoArguments"]], "benchmarkingarguments (class in lmflow.args)": [[5, "lmflow.args.BenchmarkingArguments"]], "datasetarguments (class in lmflow.args)": [[5, "lmflow.args.DatasetArguments"]], "evaluatorarguments (class in lmflow.args)": [[5, "lmflow.args.EvaluatorArguments"]], "finetunerarguments (class in lmflow.args)": [[5, "lmflow.args.FinetunerArguments"]], "inferencerarguments (class in lmflow.args)": [[5, "lmflow.args.InferencerArguments"]], "model_config_classes (in module lmflow.args)": [[5, "lmflow.args.MODEL_CONFIG_CLASSES"]], "model_types (in module lmflow.args)": [[5, "lmflow.args.MODEL_TYPES"]], "modelarguments (class in lmflow.args)": [[5, "lmflow.args.ModelArguments"]], "pipeline_argument_mapping (in module lmflow.args)": [[5, "lmflow.args.PIPELINE_ARGUMENT_MAPPING"]], "raftalignerarguments (class in lmflow.args)": [[5, "lmflow.args.RaftAlignerArguments"]], "__post_init__() (lmflow.args.datasetarguments method)": [[5, "lmflow.args.DatasetArguments.__post_init__"]], "__post_init__() (lmflow.args.modelarguments method)": [[5, "lmflow.args.ModelArguments.__post_init__"]], "answer_type (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.answer_type"]], "arch_type (lmflow.args.modelarguments attribute)": [[5, "id0"], [5, "lmflow.args.ModelArguments.arch_type"]], "block_size (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.block_size"]], "cache_dir (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.cache_dir"]], "config_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_name"]], "config_overrides (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_overrides"]], "customized_cache_dir (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.customized_cache_dir"]], "dataset_config_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_config_name"]], "dataset_name (lmflow.args.benchmarkingarguments attribute)": [[5, "lmflow.args.BenchmarkingArguments.dataset_name"]], "dataset_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_name"]], "dataset_path (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_path"]], "deepspeed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.deepspeed"]], "deepspeed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.deepspeed"]], "device (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.device"]], "disable_group_texts (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.disable_group_texts"]], "do_sample (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.do_sample"]], "eval_dataset_path (lmflow.args.finetunerarguments attribute)": [[5, "lmflow.args.FinetunerArguments.eval_dataset_path"]], "evaluate_block_size (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.evaluate_block_size"]], "get_pipeline_args_class() (lmflow.args.autoarguments method)": [[5, "lmflow.args.AutoArguments.get_pipeline_args_class"]], "group_texts_batch_size (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.group_texts_batch_size"]], "inference_batch_size_per_device (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.inference_batch_size_per_device"]], "inference_batch_size_per_device (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.inference_batch_size_per_device"]], "is_custom_dataset (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.is_custom_dataset"]], "keep_linebreaks (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.keep_linebreaks"]], "lm_evaluation_metric (lmflow.args.benchmarkingarguments attribute)": [[5, "lmflow.args.BenchmarkingArguments.lm_evaluation_metric"]], "local_rank (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.local_rank"]], "local_rank (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.local_rank"]], "lora_alpha (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_alpha"]], "lora_dropout (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_dropout"]], "lora_model_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_model_path"]], "lora_r (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_r"]], "lora_target_modules (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_target_modules"]], "max_eval_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_eval_samples"]], "max_train_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_train_samples"]], "metric (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.metric"]], "mixed_precision (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.mixed_precision"]], "mixed_precision (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.mixed_precision"]], "model_name_or_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_name_or_path"]], "model_revision (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_revision"]], "model_type (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_type"]], "num_raft_iteration (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.num_raft_iteration"]], "output_dir (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.output_dir"]], "output_max_length (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_max_length"]], "output_min_length (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_min_length"]], "output_reward_path (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_reward_path"]], "overwrite_cache (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.overwrite_cache"]], "preprocessing_num_workers (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.preprocessing_num_workers"]], "prompt_structure (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.prompt_structure"]], "raft_batch_size (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.raft_batch_size"]], "random_seed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_seed"]], "random_seed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.random_seed"]], "random_shuffle (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_shuffle"]], "save_aggregated_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.save_aggregated_lora"]], "streaming (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.streaming"]], "test_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.test_file"]], "tokenizer_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.tokenizer_name"]], "top_reward_percentage (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.top_reward_percentage"]], "torch_dtype (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.torch_dtype"]], "train_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.train_file"]], "use_accelerator_for_evaluator (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.use_accelerator_for_evaluator"]], "use_auth_token (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_auth_token"]], "use_fast_tokenizer (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_fast_tokenizer"]], "use_flash_attention (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_flash_attention"]], "use_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_lora"]], "use_ram_optimized_load (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_ram_optimized_load"]], "use_wandb (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.use_wandb"]], "validation_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_file"]], "validation_split_percentage (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_split_percentage"]], "dataset_types (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.DATASET_TYPES"]], "dataset (class in lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.Dataset"]], "key_instances (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_INSTANCES"]], "key_type (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_TYPE"]], "_check_data_format() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset._check_data_format"]], "create_from_dict() (lmflow.datasets.dataset.dataset class method)": [[6, "lmflow.datasets.dataset.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_data_args"]], "get_fingerprint() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_fingerprint"]], "get_type() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_type"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "map() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.map"]], "to_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.to_dict"]], "dataset (class in lmflow.datasets)": [[7, "lmflow.datasets.Dataset"]], "_check_data_format() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset._check_data_format"]], "create_from_dict() (lmflow.datasets.dataset class method)": [[7, "lmflow.datasets.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_data_args"]], "get_fingerprint() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_fingerprint"]], "get_type() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_type"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "map() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.map"]], "to_dict() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.to_dict"]], "__version__ (in module lmflow)": [[8, "lmflow.__version__"]], "internal_version (in module lmflow)": [[8, "lmflow.internal_version"]], "lmflow": [[8, "module-lmflow"]], "automodel (class in lmflow.models.auto_model)": [[9, "lmflow.models.auto_model.AutoModel"]], "get_model() (lmflow.models.auto_model.automodel class method)": [[9, "lmflow.models.auto_model.AutoModel.get_model"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "basemodel (class in lmflow.models.base_model)": [[10, "lmflow.models.base_model.BaseModel"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "decodermodel (class in lmflow.models.decoder_model)": [[11, "lmflow.models.decoder_model.DecoderModel"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "encoderdecodermodel (class in lmflow.models.encoder_decoder_model)": [[12, "lmflow.models.encoder_decoder_model.EncoderDecoderModel"]], "lmflow.models.encoder_decoder_model": [[12, "module-lmflow.models.encoder_decoder_model"]], "hfdecodermodel (class in lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel"]], "models_support_flash_attention (in module lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.MODELS_SUPPORT_FLASH_ATTENTION"]], "decode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.decode"]], "encode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_max_length"]], "get_tokenizer() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.inference"]], "lmflow.models.hf_decoder_model": [[13, "module-lmflow.models.hf_decoder_model"]], "logger (in module lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.save"]], "tokenize() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.tokenize"]], "hfencoderdecodermodel (class in lmflow.models.hf_encoder_decoder_model)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel"]], "decode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.decode"]], "encode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_max_length"]], "get_tokenizer() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.inference"]], "lmflow.models.hf_encoder_decoder_model": [[14, "module-lmflow.models.hf_encoder_decoder_model"]], "logger (in module lmflow.models.hf_encoder_decoder_model)": [[14, "lmflow.models.hf_encoder_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.save"]], "tokenize() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.tokenize"]], "lmflow.models": [[15, "module-lmflow.models"]], "lmflow.models.interfaces": [[16, "module-lmflow.models.interfaces"]], "tunable (class in lmflow.models.interfaces.tunable)": [[17, "lmflow.models.interfaces.tunable.Tunable"]], "lmflow.models.interfaces.tunable": [[17, "module-lmflow.models.interfaces.tunable"]], "regressionmodel (class in lmflow.models.regression_model)": [[18, "lmflow.models.regression_model.RegressionModel"]], "lmflow.models.regression_model": [[18, "module-lmflow.models.regression_model"]], "textregressionmodel (class in lmflow.models.text_regression_model)": [[19, "lmflow.models.text_regression_model.TextRegressionModel"]], "inference() (lmflow.models.text_regression_model.textregressionmodel method)": [[19, "lmflow.models.text_regression_model.TextRegressionModel.inference"]], "lmflow.models.text_regression_model": [[19, "module-lmflow.models.text_regression_model"]], "register_inference_function() (lmflow.models.text_regression_model.textregressionmodel method)": [[19, "lmflow.models.text_regression_model.TextRegressionModel.register_inference_function"]], "autopipeline (class in lmflow.pipeline.auto_pipeline)": [[20, "lmflow.pipeline.auto_pipeline.AutoPipeline"]], "pipeline_mapping (in module lmflow.pipeline.auto_pipeline)": [[20, "lmflow.pipeline.auto_pipeline.PIPELINE_MAPPING"]], "get_pipeline() (lmflow.pipeline.auto_pipeline.autopipeline class method)": [[20, "lmflow.pipeline.auto_pipeline.AutoPipeline.get_pipeline"]], "lmflow.pipeline.auto_pipeline": [[20, "module-lmflow.pipeline.auto_pipeline"]], "basealigner (class in lmflow.pipeline.base_aligner)": [[21, "lmflow.pipeline.base_aligner.BaseAligner"]], "_check_if_alignable() (lmflow.pipeline.base_aligner.basealigner method)": [[21, "lmflow.pipeline.base_aligner.BaseAligner._check_if_alignable"]], "align() (lmflow.pipeline.base_aligner.basealigner method)": [[21, "lmflow.pipeline.base_aligner.BaseAligner.align"]], "lmflow.pipeline.base_aligner": [[21, "module-lmflow.pipeline.base_aligner"]], "basepipeline (class in lmflow.pipeline.base_pipeline)": [[22, "lmflow.pipeline.base_pipeline.BasePipeline"]], "lmflow.pipeline.base_pipeline": [[22, "module-lmflow.pipeline.base_pipeline"]], "basetuner (class in lmflow.pipeline.base_tuner)": [[23, "lmflow.pipeline.base_tuner.BaseTuner"]], "_check_if_tunable() (lmflow.pipeline.base_tuner.basetuner method)": [[23, "lmflow.pipeline.base_tuner.BaseTuner._check_if_tunable"]], "lmflow.pipeline.base_tuner": [[23, "module-lmflow.pipeline.base_tuner"]], "tune() (lmflow.pipeline.base_tuner.basetuner method)": [[23, "lmflow.pipeline.base_tuner.BaseTuner.tune"]], "evaluator (class in lmflow.pipeline.evaluator)": [[24, "lmflow.pipeline.evaluator.Evaluator"]], "_evaluate_acc_with_accelerator() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc_with_accelerator"]], "_evaluate_acc_with_deepspeed() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc_with_deepspeed"]], "_evaluate_nll() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_nll"]], "_evaluate_ppl() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_ppl"]], "_match() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._match"]], "create_dataloader() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator.create_dataloader"]], "evaluate() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator.evaluate"]], "lmflow.pipeline.evaluator": [[24, "module-lmflow.pipeline.evaluator"]], "finetuner (class in lmflow.pipeline.finetuner)": [[25, "lmflow.pipeline.finetuner.Finetuner"]], "group_text() (lmflow.pipeline.finetuner.finetuner method)": [[25, "lmflow.pipeline.finetuner.Finetuner.group_text"]], "lmflow.pipeline.finetuner": [[25, "module-lmflow.pipeline.finetuner"]], "logger (in module lmflow.pipeline.finetuner)": [[25, "lmflow.pipeline.finetuner.logger"]], "tune() (lmflow.pipeline.finetuner.finetuner method)": [[25, "lmflow.pipeline.finetuner.Finetuner.tune"]], "lmflow.pipeline": [[26, "module-lmflow.pipeline"]], "inferencer (class in lmflow.pipeline.inferencer)": [[27, "lmflow.pipeline.inferencer.Inferencer"]], "create_dataloader() (lmflow.pipeline.inferencer.inferencer method)": [[27, "lmflow.pipeline.inferencer.Inferencer.create_dataloader"]], "inference() (lmflow.pipeline.inferencer.inferencer method)": [[27, "lmflow.pipeline.inferencer.Inferencer.inference"]], "lmflow.pipeline.inferencer": [[27, "module-lmflow.pipeline.inferencer"]], "rstrip_partial_utf8() (in module lmflow.pipeline.inferencer)": [[27, "lmflow.pipeline.inferencer.rstrip_partial_utf8"]], "stream_inference() (lmflow.pipeline.inferencer.inferencer method)": [[27, "lmflow.pipeline.inferencer.Inferencer.stream_inference"]], "raftaligner (class in lmflow.pipeline.raft_aligner)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner"]], "_get_batch_dataset_top() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._get_batch_dataset_top"]], "_initialize_trainer() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._initialize_trainer"]], "_load_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._load_dataset"]], "_load_input_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._load_input_dataset"]], "align() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner.align"]], "lmflow.pipeline.raft_aligner": [[28, "module-lmflow.pipeline.raft_aligner"]], "logger (in module lmflow.pipeline.raft_aligner)": [[28, "lmflow.pipeline.raft_aligner.logger"]], "lmflow.pipeline.utils": [[29, "module-lmflow.pipeline.utils"]], "default_callbacks (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.DEFAULT_CALLBACKS"]], "default_progress_callback (in module lmflow.pipeline.utils.raft_trainer)": [[30, "id0"], [30, "lmflow.pipeline.utils.raft_trainer.DEFAULT_PROGRESS_CALLBACK"]], "is_sagemaker_mp_post_1_10 (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.IS_SAGEMAKER_MP_POST_1_10"]], "optimizer_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.OPTIMIZER_NAME"]], "rafttrainer (class in lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer"]], "scaler_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.SCALER_NAME"]], "scheduler_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.SCHEDULER_NAME"]], "trainer_state_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.TRAINER_STATE_NAME"]], "training_args_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.TRAINING_ARGS_NAME"]], "_add_sm_patterns_to_gitignore() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._add_sm_patterns_to_gitignore"]], "_gather_and_numpify() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._gather_and_numpify"]], "_get_collator_with_removed_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_collator_with_removed_columns"]], "_get_eval_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_eval_sampler"]], "_get_output_dir() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_output_dir"]], "_get_train_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_train_sampler"]], "_hp_search_setup() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._hp_search_setup"]], "_inner_training_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._inner_training_loop"]], "_is_native_cpu_amp_available (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer._is_native_cpu_amp_available"]], "_issue_warnings_after_load() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._issue_warnings_after_load"]], "_load_best_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_best_model"]], "_load_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_from_checkpoint"]], "_load_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_optimizer_and_scheduler"]], "_load_rng_state() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_rng_state"]], "_maybe_log_save_evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._maybe_log_save_evaluate"]], "_move_model_to_device() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._move_model_to_device"]], "_nested_gather() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._nested_gather"]], "_one_train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._one_train"]], "_pad_across_processes() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._pad_across_processes"]], "_prepare_input() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_input"]], "_prepare_inputs() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_inputs"]], "_push_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._push_from_checkpoint"]], "_remove_unused_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._remove_unused_columns"]], "_report_to_hp_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._report_to_hp_search"]], "_rotate_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._rotate_checkpoints"]], "_save() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save"]], "_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_checkpoint"]], "_save_tpu() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_tpu"]], "_set_signature_columns_if_needed() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._set_signature_columns_if_needed"]], "_sorted_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._sorted_checkpoints"]], "_tune_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._tune_save_checkpoint"]], "_wrap_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._wrap_model"]], "add_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.add_callback"]], "autocast_smart_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.autocast_smart_context_manager"]], "call_model_init() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.call_model_init"]], "compute_loss() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss"]], "compute_loss_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss_context_manager"]], "create_model_card() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_model_card"]], "create_optimizer() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer"]], "create_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer_and_scheduler"]], "create_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_scheduler"]], "evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluate"]], "evaluation_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluation_loop"]], "floating_point_ops() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.floating_point_ops"]], "get_eval_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_eval_dataloader"]], "get_optimizer_cls_and_kwargs() (lmflow.pipeline.utils.raft_trainer.rafttrainer static method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_optimizer_cls_and_kwargs"]], "get_test_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_test_dataloader"]], "get_train_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_train_dataloader"]], "hyperparameter_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.hyperparameter_search"]], "init_git_repo() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.init_git_repo"]], "ipex_optimize_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.ipex_optimize_model"]], "is_local_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_local_process_zero"]], "is_world_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_world_process_zero"]], "lmflow.pipeline.utils.raft_trainer": [[30, "module-lmflow.pipeline.utils.raft_trainer"]], "log() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.log"]], "logger (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.logger"]], "num_examples() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.num_examples"]], "pop_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.pop_callback"]], "predict() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.predict"]], "prediction_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_loop"]], "prediction_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_step"]], "push_to_hub() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.push_to_hub"]], "remove_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.remove_callback"]], "save_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.save_model"]], "skip_first_batches (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.skip_first_batches"]], "store_flos() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.store_flos"]], "torch_jit_model_eval() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.torch_jit_model_eval"]], "train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.train"]], "training_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.training_step"]], "dataset_description_map (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.DATASET_DESCRIPTION_MAP"]], "float_only_dataset_description (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.FLOAT_ONLY_DATASET_DESCRIPTION"]], "instance_fields_map (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.INSTANCE_FIELDS_MAP"]], "text2text_dataset_description (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT2TEXT_DATASET_DESCRIPTION"]], "text2text_dataset_details (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT2TEXT_DATASET_DETAILS"]], "text2text_dataset_long_descrition (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT2TEXT_DATASET_LONG_DESCRITION"]], "text_only_dataset_description (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT_ONLY_DATASET_DESCRIPTION"]], "text_only_dataset_details (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT_ONLY_DATASET_DETAILS"]], "text_only_dataset_long_descrition (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT_ONLY_DATASET_LONG_DESCRITION"]], "lmflow.utils.constants": [[31, "module-lmflow.utils.constants"]], "answer_extraction() (in module lmflow.utils.data_utils)": [[32, "lmflow.utils.data_utils.answer_extraction"]], "batchlize() (in module lmflow.utils.data_utils)": [[32, "lmflow.utils.data_utils.batchlize"]], "lmflow.utils.data_utils": [[32, "module-lmflow.utils.data_utils"]], "load_data() (in module lmflow.utils.data_utils)": [[32, "lmflow.utils.data_utils.load_data"]], "set_random_seed() (in module lmflow.utils.data_utils)": [[32, "lmflow.utils.data_utils.set_random_seed"]], "_attn() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[33, "lmflow.utils.flash_attention.gpt_neo_flash_attention._attn"]], "forward() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[33, "lmflow.utils.flash_attention.gpt_neo_flash_attention.forward"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[33, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"]], "replace_gpt_neo_attn_with_flash_attn() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[33, "lmflow.utils.flash_attention.gpt_neo_flash_attention.replace_gpt_neo_attn_with_flash_attn"]], "lmflow.utils.flash_attention": [[34, "module-lmflow.utils.flash_attention"]], "_prepare_decoder_attention_mask() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[35, "lmflow.utils.flash_attention.llama_flash_attention._prepare_decoder_attention_mask"]], "forward() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[35, "lmflow.utils.flash_attention.llama_flash_attention.forward"]], "lmflow.utils.flash_attention.llama_flash_attention": [[35, "module-lmflow.utils.flash_attention.llama_flash_attention"]], "replace_llama_attn_with_flash_attn() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[35, "lmflow.utils.flash_attention.llama_flash_attention.replace_llama_attn_with_flash_attn"]], "lmflow.utils": [[36, "module-lmflow.utils"]], "__version__ (in module lmflow.version)": [[37, "lmflow.version.__version__"]], "lmflow.version": [[37, "module-lmflow.version"]]}})